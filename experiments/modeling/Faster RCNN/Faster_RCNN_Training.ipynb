{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Faster_RCNN_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhzxsJb3dpWq"
      },
      "source": [
        "## Configs and Hyperparameters\n",
        "\n",
        "Support a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNXNQCjdniL"
      },
      "source": [
        "# If you forked the repo, you can replace the link.\n",
        "repo_url = 'https://github.com/roboflow-ai/tensorflow-object-detection-faster-rcnn'\n",
        "\n",
        "# Number of training steps - 1000 will train very quickly, but more steps will increase accuracy.\n",
        "num_steps = 10000  # 200000 to improve\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    },    \n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'faster_rcnn_inception_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL8oRGC5UgMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7377afa7-cd93-41e5-d8a3-2a7af63c2d61"
      },
      "source": [
        "# use TF 1.x for Object Detection APIs as they are not ported to TF 2.0 yet\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kajn-8M_MaUU",
        "outputId": "729ecd78-28b5-4155-f4a5-676ba9070adb"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"You are using TensorFlow version\", tf .__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are using TensorFlow version 1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4V-XE6kbkc1"
      },
      "source": [
        "## Clone the `tensorflow-object-detection` repository or your fork."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxc3DmvLQF3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d33cc4f-58dd-4f59-8288-f5f97849c904"
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'tensorflow-object-detection-faster-rcnn'...\n",
            "remote: Enumerating objects: 885, done.\u001b[K\n",
            "remote: Total 885 (delta 0), reused 0 (delta 0), pack-reused 885\u001b[K\n",
            "Receiving objects: 100% (885/885), 24.83 MiB | 16.77 MiB/s, done.\n",
            "Resolving deltas: 100% (428/428), done.\n",
            "/content/tensorflow-object-detection-faster-rcnn\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI8__uNS8-ns"
      },
      "source": [
        "## Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecpHEnka8Kix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "302e0503-44c4-4c2b-8f8e-5386fa125d6a"
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!pip install tf_slim\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "!pip install lvis\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 160980 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.5_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.5) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.5) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting lvis\n",
            "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.2.2)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.29.22)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.8.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.10.0)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.3.1)\n",
            "Installing collected packages: lvis\n",
            "Successfully installed lvis-0.5.3\n",
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1DgFBQ8yCeA"
      },
      "source": [
        "**Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-_7FhXuyAtw",
        "outputId": "dc6d4c81-22c6-41fe-86d8-1ade80ea15ad"
      },
      "source": [
        "#mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkZ9o7QiyMmo",
        "outputId": "76bf26d9-1fae-4ad2-8f88-b9b55c7b0783"
      },
      "source": [
        "#training folder\n",
        "!cp -r \"/content/gdrive/MyDrive/Juice_Box/FRCNN/train.zip\" \"/content/tensorflow-object-detection-faster-rcnn/data\"\n",
        "!unzip '/content/tensorflow-object-detection-faster-rcnn/data/train.zip' -d '/content/tensorflow-object-detection-faster-rcnn/data'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/tensorflow-object-detection-faster-rcnn/data/train.zip\n",
            "   creating: /content/tensorflow-object-detection-faster-rcnn/data/round2/\n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle10_jpg.rf.94e003f8976d8ab19a4bf6e9c1357a14.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle10_jpg.rf.94e003f8976d8ab19a4bf6e9c1357a14.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle11_jpg.rf.5aea207a1525a5d0bc153f5b85becc2d.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle11_jpg.rf.5aea207a1525a5d0bc153f5b85becc2d.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle12_jpg.rf.7e2c63fd733f0c7c921a73dee3e0ef9f.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle12_jpg.rf.7e2c63fd733f0c7c921a73dee3e0ef9f.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle13_jpg.rf.963d81fb784379c858201fbf7e7c50d3.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle13_jpg.rf.963d81fb784379c858201fbf7e7c50d3.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle14_jpg.rf.24ff1aa17b40c9e3d9591a725fbeb723.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle14_jpg.rf.24ff1aa17b40c9e3d9591a725fbeb723.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle15_jpg.rf.e589c91757fe0179107caaa4ed080710.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle15_jpg.rf.e589c91757fe0179107caaa4ed080710.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle16_jpg.rf.db349d18ca6cf33a75b03f7d70099603.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle16_jpg.rf.db349d18ca6cf33a75b03f7d70099603.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle17_jpg.rf.53877d2c50116a6b67671130071b1854.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle17_jpg.rf.53877d2c50116a6b67671130071b1854.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle18_jpg.rf.280ee97482e8fafb56be0c3b4557cd75.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle18_jpg.rf.280ee97482e8fafb56be0c3b4557cd75.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle19_jpg.rf.b3efe2cba4da50c9a1f6cea40355bec3.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle19_jpg.rf.b3efe2cba4da50c9a1f6cea40355bec3.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle1_jpg.rf.701ea564d2a9dd5cdd1c56c239bda73e.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle1_jpg.rf.701ea564d2a9dd5cdd1c56c239bda73e.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle20_jpg.rf.33def72ae65d654f05d607c44e02c5a8.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle20_jpg.rf.33def72ae65d654f05d607c44e02c5a8.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle21_jpg.rf.183e836b6f3d0cf472b717dcf6f2f714.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle21_jpg.rf.183e836b6f3d0cf472b717dcf6f2f714.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle22_jpg.rf.cc2e3cec0f69c643fad3a7ff01f72b90.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle22_jpg.rf.cc2e3cec0f69c643fad3a7ff01f72b90.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle23_jpg.rf.dba42429a65d16e89b323acc04836525.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle23_jpg.rf.dba42429a65d16e89b323acc04836525.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle24_jpeg.rf.efe40d6c1a75e05252ab71c56b04ab02.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle24_jpeg.rf.efe40d6c1a75e05252ab71c56b04ab02.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle25_jpeg.rf.813e358c8b402fd9c0f53ed8170a50a8.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle25_jpeg.rf.813e358c8b402fd9c0f53ed8170a50a8.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle26_jpeg.rf.f0c8f925f4b2d2d1a1a3362864057684.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle26_jpeg.rf.f0c8f925f4b2d2d1a1a3362864057684.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle27_jpeg.rf.7e420bac512c4099b094679d439130b3.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle27_jpeg.rf.7e420bac512c4099b094679d439130b3.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle2_jpg.rf.3462005e2d30a1dea21ef7bc25251698.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle2_jpg.rf.3462005e2d30a1dea21ef7bc25251698.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle3_jpg.rf.e9b0f8a688cf17944ad67bf545a4f4cc.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle3_jpg.rf.e9b0f8a688cf17944ad67bf545a4f4cc.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle4_jpg.rf.59fd1127fa15b03038a1c8c38d3e47ff.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle4_jpg.rf.59fd1127fa15b03038a1c8c38d3e47ff.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle5_jpg.rf.bd309b6f04c598057128b2bacccb4d52.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle5_jpg.rf.bd309b6f04c598057128b2bacccb4d52.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle6_jpg.rf.2b01e177e8245d618d92b9c3d9d38dca.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle6_jpg.rf.2b01e177e8245d618d92b9c3d9d38dca.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle7_jpg.rf.3aa7bc41fb768449e65b5bf466bbb07c.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle7_jpg.rf.3aa7bc41fb768449e65b5bf466bbb07c.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle8_jpg.rf.a31c4feaa0c9dc68c06070c5b6a13121.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle8_jpg.rf.a31c4feaa0c9dc68c06070c5b6a13121.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle9_jpg.rf.7160f302cef3410f311f5096d552885a.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle9_jpg.rf.7160f302cef3410f311f5096d552885a.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup10_jpeg.rf.a9a89506f4fde3ae33b6c3fcf4810376.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup10_jpeg.rf.a9a89506f4fde3ae33b6c3fcf4810376.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup11_jpeg.rf.7f4e2ce7748032e34e4cd33dc707f7c0.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup11_jpeg.rf.7f4e2ce7748032e34e4cd33dc707f7c0.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup12_jpg.rf.1599390555440b2952f18c784c63eb6d.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup12_jpg.rf.1599390555440b2952f18c784c63eb6d.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup13_jpeg.rf.8a73dc23062d8c2431401f70b87ad401.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup13_jpeg.rf.8a73dc23062d8c2431401f70b87ad401.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup14_jpeg.rf.14ae63c5a5901719f7774bd44fcc7e28.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup14_jpeg.rf.14ae63c5a5901719f7774bd44fcc7e28.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup15_jpeg.rf.f204c9eeda76fdd24143255b008d8427.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup15_jpeg.rf.f204c9eeda76fdd24143255b008d8427.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup16_jpeg.rf.939eee2f062e3f42e221b369c9be48f3.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup16_jpeg.rf.939eee2f062e3f42e221b369c9be48f3.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup17_jpeg.rf.df543dc854bb83443e4001dfa360e02a.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup17_jpeg.rf.df543dc854bb83443e4001dfa360e02a.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup18_jpeg.rf.e124eebc9d17e7acca006c6fedbb9034.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup18_jpeg.rf.e124eebc9d17e7acca006c6fedbb9034.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup19_jpeg.rf.81b9eb168479c01fa87455e583e4c49d.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup19_jpeg.rf.81b9eb168479c01fa87455e583e4c49d.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup1_jpg.rf.816d7642f4264fde77d83d50416d6ebc.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup1_jpg.rf.816d7642f4264fde77d83d50416d6ebc.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup20_jpeg.rf.731a1178170b21989f053e8282017215.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup20_jpeg.rf.731a1178170b21989f053e8282017215.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup21_jpeg.rf.ebbd63bf9a0928afe03ebdce1c6544c2.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup21_jpeg.rf.ebbd63bf9a0928afe03ebdce1c6544c2.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup2_jpg.rf.810467b7d994d59c83bbe015c6c9b6ef.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup2_jpg.rf.810467b7d994d59c83bbe015c6c9b6ef.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup3_jpg.rf.841e42c45e556943d9b7d0b0678ba45e.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup3_jpg.rf.841e42c45e556943d9b7d0b0678ba45e.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup4_jpg.rf.c98c3624b8465bcbeeffda4ba2297594.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup4_jpg.rf.c98c3624b8465bcbeeffda4ba2297594.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup5_jpeg.rf.a45c01d79fc43cca6da92db90b1ff925.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup5_jpeg.rf.a45c01d79fc43cca6da92db90b1ff925.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup6_jpeg.rf.1de80883207a5eb67f1446e92019db0d.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup6_jpeg.rf.1de80883207a5eb67f1446e92019db0d.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup7_jpeg.rf.500c5f5e6186cff0f28e0a4ac696673a.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup7_jpeg.rf.500c5f5e6186cff0f28e0a4ac696673a.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup8_jpeg.rf.cd09f8f99cf083b979500b1171fbf2dd.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup8_jpeg.rf.cd09f8f99cf083b979500b1171fbf2dd.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup9_jpeg.rf.b72482de80ff9829d5f630bf44e912f6.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup9_jpeg.rf.b72482de80ff9829d5f630bf44e912f6.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can10_jpg.rf.6b900bc75f147f86612d5e420f73ca56.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can10_jpg.rf.6b900bc75f147f86612d5e420f73ca56.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can11_jpeg.rf.b5e0463ae8b03bed92abbb07e4a533d5.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can11_jpeg.rf.b5e0463ae8b03bed92abbb07e4a533d5.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can12_jpeg.rf.aca2af7dadb47e4e0a7f35c54220e983.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can12_jpeg.rf.aca2af7dadb47e4e0a7f35c54220e983.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can13_jpg.rf.11703c7feb6f756273f4ea707b8a3aca.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can13_jpg.rf.11703c7feb6f756273f4ea707b8a3aca.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can14_jpg.rf.1c59e29e43e458c1136d04a6c575a4e7.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can14_jpg.rf.1c59e29e43e458c1136d04a6c575a4e7.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can15_jpg.rf.23836041d7fe41ab166b314afae0e655.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can15_jpg.rf.23836041d7fe41ab166b314afae0e655.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can16_jpeg.rf.ffdc9cdedc2d7d3787ddae8f29536f2e.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can16_jpeg.rf.ffdc9cdedc2d7d3787ddae8f29536f2e.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can17_jpg.rf.6409d16affc79a9370f0867c148f2908.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can17_jpg.rf.6409d16affc79a9370f0867c148f2908.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can18_jpg.rf.e8eb14e911cdad2eb7f0f641996f0385.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can18_jpg.rf.e8eb14e911cdad2eb7f0f641996f0385.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can19_jpg.rf.37bec0641dd26ae4c020fca203588996.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can19_jpg.rf.37bec0641dd26ae4c020fca203588996.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can1_jpg.rf.5147a79c48d3b160605cfe551bfc0ad9.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can1_jpg.rf.5147a79c48d3b160605cfe551bfc0ad9.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can20_jpeg.rf.575319eaef9d356a70c642961b8da9b0.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can20_jpeg.rf.575319eaef9d356a70c642961b8da9b0.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can21_jpg.rf.a2f71883e1dcf73baf1d3003c43016a7.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can21_jpg.rf.a2f71883e1dcf73baf1d3003c43016a7.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can2_jpg.rf.ae0ce94d9fc47c77daa5bae32ab92b2f.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can2_jpg.rf.ae0ce94d9fc47c77daa5bae32ab92b2f.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can3_jpg.rf.f0b5b7f391f75c508a34545c5f0e4464.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can3_jpg.rf.f0b5b7f391f75c508a34545c5f0e4464.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can4_jpg.rf.44ab3e63e958be7ff2ac69ad942d2fbc.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can4_jpg.rf.44ab3e63e958be7ff2ac69ad942d2fbc.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can5_jpg.rf.818dfe3bf9a9f7f75e576573eb557afc.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can5_jpg.rf.818dfe3bf9a9f7f75e576573eb557afc.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can6_jpg.rf.c3920307aff7821d6448f6a8c61860f7.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can6_jpg.rf.c3920307aff7821d6448f6a8c61860f7.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can7_jpg.rf.4037d5573fccdc1a142cc28bd7c9d488.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can7_jpg.rf.4037d5573fccdc1a142cc28bd7c9d488.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can8_jpg.rf.13618e8f955864d13100c89fcd0463e0.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can8_jpg.rf.13618e8f955864d13100c89fcd0463e0.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can9_jpg.rf.cc0b8952520a850a77f427714dcc3fe8.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can9_jpg.rf.cc0b8952520a850a77f427714dcc3fe8.xml  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY-D9fI0yTFA"
      },
      "source": [
        "#test folder\n",
        "!cp -r \"/content/gdrive/MyDrive/Juice_Box/FRCNN/test\" \"/content/tensorflow-object-detection-faster-rcnn/data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0WJyXrJylVq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PKbBYdy6yf90",
        "outputId": "98a62bfa-a12b-4caa-a9a1-45385daea89f"
      },
      "source": [
        "!pip install tensorflow-object-detection-api"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-object-detection-api\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/11/7f6d3c5c4b603cc40b2813059779afb641bd5eb68045c62ca520bfce0359/tensorflow_object_detection_api-0.1.1.tar.gz (577kB)\n",
            "\r\u001b[K     |▋                               | 10kB 14.6MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 13.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 11.5MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 11.2MB/s eta 0:00:01\r\u001b[K     |██▉                             | 51kB 8.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 61kB 7.4MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 8.3MB/s eta 0:00:01\r\u001b[K     |████▌                           | 81kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 92kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 102kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 112kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 122kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 133kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 143kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 153kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 163kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 174kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 184kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 194kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 204kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 215kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 225kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 235kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 245kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 256kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 266kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 276kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 286kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 296kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 307kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 317kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 327kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 337kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 348kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 358kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 368kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 378kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 389kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 399kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 409kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 419kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 430kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 440kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 450kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 460kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 471kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 481kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 491kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 501kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 512kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 522kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 532kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 542kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 552kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 563kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 573kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 583kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (7.0.0)\n",
            "Requirement already satisfied: Matplotlib>=2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (3.2.2)\n",
            "Requirement already satisfied: Cython>=0.28.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.29.22)\n",
            "Requirement already satisfied: Protobuf in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (3.12.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (4.2.6)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (1.0.0)\n",
            "Requirement already satisfied: tensorflow in /tensorflow-1.15.2/python3.7 (from tensorflow-object-detection-api) (1.15.2)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.5.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.36.2)\n",
            "Collecting twine\n",
            "  Downloading https://files.pythonhosted.org/packages/42/ad/713372978a8de58a43c507bf62b9c30c3d7b5cda4e972d563b881620a511/twine-3.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (2.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from Protobuf->tensorflow-object-detection-api) (54.1.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from Protobuf->tensorflow-object-detection-api) (1.15.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (4.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.3.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (7.6.3)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.0.3)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.2.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.6.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.2/python3.7 (from tensorflow->tensorflow-object-detection-api) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.1.2)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.2/python3.7 (from tensorflow->tensorflow-object-detection-api) (1.15.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-1.15.2/python3.7 (from tensorflow->tensorflow-object-detection-api) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.32.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.1.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (2.23.0)\n",
            "Collecting pkginfo>=1.4.2\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/d78e7c299eb5659bc3a036e5a968a399c62bfe0b2aa18baf7d13f43373ba/pkginfo-1.7.0-py2.py3-none-any.whl\n",
            "Collecting colorama>=0.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.14 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (4.41.1)\n",
            "Collecting requests-toolbelt!=0.9.0,>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.9MB/s \n",
            "\u001b[?25hCollecting readme-renderer>=21.0\n",
            "  Downloading https://files.pythonhosted.org/packages/39/a5/459adfa22ea237f6e8d0fa95ad29d7369579a5eec26f016ab34bb7f8359c/readme_renderer-29.0-py2.py3-none-any.whl\n",
            "Collecting keyring>=15.1\n",
            "  Downloading https://files.pythonhosted.org/packages/26/f9/41230ac47f738f1ba66676dc8d3b30ca5b1f9eb0230fc204bcd9836c4ae9/keyring-23.0.1-py3-none-any.whl\n",
            "Collecting rfc3986>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/78/be/7b8b99fd74ff5684225f50dd0e865393d2265656ef3b4ba9eaaaffe622b8/rfc3986-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (3.7.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.0.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (2.11.3)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (4.7.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (1.5.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (0.2.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (0.9.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (5.1.2)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (3.5.1)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->tensorflow-object-detection-api) (22.0.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->tensorflow-object-detection-api) (2.6.1)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->tensorflow-object-detection-api) (1.9.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->tensorflow-object-detection-api) (1.0.18)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.4.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (1.4.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (3.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow->tensorflow-object-detection-api) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow->tensorflow-object-detection-api) (3.3.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow->tensorflow-object-detection-api) (2.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->twine->tensorflow-object-detection-api) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->twine->tensorflow-object-detection-api) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->twine->tensorflow-object-detection-api) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->twine->tensorflow-object-detection-api) (3.0.4)\n",
            "Requirement already satisfied: docutils>=0.13.1 in /usr/local/lib/python3.7/dist-packages (from readme-renderer>=21.0->twine->tensorflow-object-detection-api) (0.16)\n",
            "Collecting jeepney>=0.4.2; sys_platform == \"linux\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/b0/a6ea72741aaac3f37fb96d195e4ee576a103c4c04e279bc6b446a70960e1/jeepney-0.6.0-py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n",
            "\u001b[?25hCollecting SecretStorage>=3.2; sys_platform == \"linux\"\n",
            "  Downloading https://files.pythonhosted.org/packages/d9/1e/29cd69fdac7391aa51510dfd42aa70b4e6a826c8cd019ee2a8ab9ec0777f/SecretStorage-3.3.1-py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->twine->tensorflow-object-detection-api) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->twine->tensorflow-object-detection-api) (3.4.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.7.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->tensorflow-object-detection-api) (1.1.1)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->tensorflow-object-detection-api) (0.7.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->tensorflow-object-detection-api) (2.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->tensorflow-object-detection-api) (0.2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->tensorflow-object-detection-api) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->tensorflow-object-detection-api) (20.9)\n",
            "Collecting cryptography>=2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 16.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->SecretStorage>=3.2; sys_platform == \"linux\"->keyring>=15.1->twine->tensorflow-object-detection-api) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2; sys_platform == \"linux\"->keyring>=15.1->twine->tensorflow-object-detection-api) (2.20)\n",
            "Building wheels for collected packages: tensorflow-object-detection-api, gast\n",
            "  Building wheel for tensorflow-object-detection-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-object-detection-api: filename=tensorflow_object_detection_api-0.1.1-cp37-none-any.whl size=844515 sha256=f39dfe2eb2ffb87cc55596934bdd792334719a9702a4a74e308cbc51df212b63\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/54/d0/cfca11930c4b2025d40dede77059094070a67cc3e7bd3b285f\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=1faf47c32f0026af18eb77cf1bfb010f503ff70a5fa404a47a68415926c1ed96\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built tensorflow-object-detection-api gast\n",
            "Installing collected packages: pkginfo, colorama, requests-toolbelt, readme-renderer, jeepney, cryptography, SecretStorage, keyring, rfc3986, twine, tensorflow-object-detection-api, gast\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed SecretStorage-3.3.1 colorama-0.4.4 cryptography-3.4.7 gast-0.2.2 jeepney-0.6.0 keyring-23.0.1 pkginfo-1.7.0 readme-renderer-29.0 requests-toolbelt-0.9.1 rfc3986-1.4.0 tensorflow-object-detection-api-0.1.1 twine-3.4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERsjE4DryzpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2631b07d-9f0f-444c-ab85-09add823bf84"
      },
      "source": [
        "#Generate csv for train and test labels\n",
        "!if [ -d '/content/tensorflow-object-detection-faster-rcnn/data/annotations' ]; then rm -r /content/tensorflow-object-detection-faster-rcnn/data/annotations/* ; else mkdir '/content/tensorflow-object-detection-faster-rcnn/data/annotations' && echo \"Directory annotations created\"; fi\n",
        "\n",
        "if os.path.exists(\"/content/tensorflow-object-detection-faster-rcnn/data/annotations/train_labels.csv\"):\n",
        "    os.remove(\"/content/tensorflow-object-detection-faster-rcnn/data/annotations/train_labels.csv\")\n",
        "\n",
        "if os.path.exists(\"/content/tensorflow-object-detection-faster-rcnn/data/annotations/test_labels.csv\"):\n",
        "    os.remove(\"/content/tensorflow-object-detection-faster-rcnn/data/annotations/test_labels.csv\")  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/tensorflow-object-detection-faster-rcnn/data/annotations/*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJUEEdZny5A8",
        "outputId": "87d8943a-77ef-4905-a83e-ab11d767a19d"
      },
      "source": [
        "#Generate csv for train and test labels within annotations folder\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import shutil\n",
        "\n",
        "annotations = r'/content/tensorflow-object-detection-faster-rcnn/data' \n",
        "if not os.path.exists(annotations):\n",
        "    os.makedirs(annotations)\n",
        "\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            bndbox = member.find('bndbox')\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member.find('name').text,\n",
        "                     int(bndbox.find('xmin').text),\n",
        "                     int(bndbox.find('ymin').text),\n",
        "                     int(bndbox.find('xmax').text),\n",
        "                     int(bndbox.find('ymax').text)\n",
        "                     )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "\n",
        "\n",
        "def main():\n",
        "    xml_df_train = xml_to_csv(\"/content/tensorflow-object-detection-faster-rcnn/data/train/\")\n",
        "    xml_df_train.to_csv('/content/tensorflow-object-detection-faster-rcnn/data/annotations/'+'train_labels.csv', index=None)\n",
        "    xml_df_test = xml_to_csv(\"/content/tensorflow-object-detection-faster-rcnn/data/test/\")\n",
        "    xml_df_test.to_csv('/content/tensorflow-object-detection-faster-rcnn/data/annotations/'+'test_labels.csv', index=None)\n",
        "    print('Successfully converted xml to csv.')\n",
        "\n",
        "%cd \"/content/tensorflow-object-detection-faster-rcnn\"\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/tensorflow-object-detection-faster-rcnn\n",
            "Successfully converted xml to csv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTMSHv30zACo"
      },
      "source": [
        "# Generate tf_label_map.pbtxt in train folder for the classes generated\n",
        "ssd_classes=pd.DataFrame(pd.read_csv(\"/content/tensorflow-object-detection-faster-rcnn/data/annotations/train_labels.csv\")['class'].unique())\n",
        "ssd_classes.drop_duplicates(inplace=True)\n",
        "\n",
        "ssd_classes['id'] = ssd_classes.index\n",
        "\n",
        "def convert_classes(classes, start=1):\n",
        "    msg = ''\n",
        "    for id, name in enumerate(classes, start=start):\n",
        "        msg = msg + \"item {\\n\"\n",
        "        msg = msg + \" id: \" + str(id) + \"\\n\"\n",
        "        msg = msg + \" name: '\" + name + \"'\\n}\\n\\n\"\n",
        "    return msg[:-1]\n",
        "\n",
        "label_map = convert_classes(ssd_classes[0])\n",
        "with open(\"/content/tensorflow-object-detection-faster-rcnn/data/train/\" + \"label_map.pbtxt\", \"w\") as f:\n",
        "    f.write(label_map)\n",
        "    f.close()    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P2YePv9z9lQ"
      },
      "source": [
        "# Generate TF record - Run for train\n",
        "%%capture\n",
        "%cd {repo_dir_path}\n",
        "#FLAGS.remove_flag_values(FLAGS.flag_values_dict())\n",
        "\n",
        "\"\"\"\n",
        "Usage:\n",
        "# Create train data:\n",
        "python generate_tfrecord.py --label_map=<PATH_TO_LABEL_MAP_FILE> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/\n",
        "train_labels.csv --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/train.record\n",
        "\n",
        "# Create test data:\n",
        "python generate_tfrecord.py --label_map=<PATH_TO_LABEL_MAP_FILE> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/\n",
        "test_labels.csv --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/test.record\n",
        "\"\"\"\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"../../models/research\")\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "flags = tf.compat.v1.app.flags\n",
        "flags.DEFINE_string('f','','')\n",
        "flags.DEFINE_string('csv_input', '', 'Path to the CSV input')\n",
        "flags.DEFINE_string('output_path', '', 'Path to output TFRecord')\n",
        "flags.DEFINE_string('img_path', '', 'Path to images')\n",
        "flags.DEFINE_string('label_map', '', 'Path to label map (.pbtxt) file')\n",
        "\n",
        "# if your image has more labels input them as\n",
        "# flags.DEFINE_string('label0', '', 'Name of class[0] label')\n",
        "# flags.DEFINE_string('label1', '', 'Name of class[1] label')\n",
        "# and so on.\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "def class_text_to_int(row_label):\n",
        "    for label_id, label_name in get_label_info():\n",
        "        if row_label == label_name:\n",
        "            return label_id\n",
        "    return 0\n",
        "\n",
        "\n",
        "def get_label_info():\n",
        "    \"\"\"\n",
        "    Generate label info from label map (.pbtxt) file\n",
        "    :return: id, name\n",
        "    \"\"\"\n",
        "    label_info = []\n",
        "    with open(FLAGS.label_map) as fp:\n",
        "        for _, line in enumerate(fp):\n",
        "            if \"id:\" in line:\n",
        "                label_id = int(line.split(\":\")[1])\n",
        "                label_info.append(label_id)\n",
        "            elif \"name:\" in line:\n",
        "                label_name = line.split(\":\")[1].strip().replace(\"'\", \"\")\n",
        "                label_info.append(label_name)\n",
        "\n",
        "    for i in range(0, len(label_info), 2):\n",
        "        yield label_info[i:i + 2]\n",
        "\n",
        "\n",
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    width, height = image.size\n",
        "    filename = group.filename.encode('utf8')\n",
        "    image_format = b'jpg'\n",
        "\n",
        "    # check if the image format is matching with your images.\n",
        "    xmins = []\n",
        "    xmaxs = []\n",
        "    ymins = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for index, row in group.object.iterrows():\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(row['class'].encode('utf8'))\n",
        "        classes.append(class_text_to_int(row['class']))\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "\n",
        "def main(_):\n",
        "    FLAGS.output_path=\"/content/tensorflow-object-detection-faster-rcnn/data/train/train.tfrecord\"\n",
        "    FLAGS.csv_input=\"/content/tensorflow-object-detection-faster-rcnn/data/annotations/train_labels.csv\"\n",
        "    FLAGS.img_path=\"/content/tensorflow-object-detection-faster-rcnn/data/train\"\n",
        "    FLAGS.label_map =\"/content/tensorflow-object-detection-faster-rcnn/data/train/label_map.pbtxt\"\n",
        "    \n",
        "    writer = tf.io.TFRecordWriter(\"/content/tensorflow-object-detection-faster-rcnn/data/train/train.tfrecord\")\n",
        "    path = os.path.join(os.getcwd(), FLAGS.img_path)\n",
        "    examples = pd.read_csv(FLAGS.csv_input)\n",
        "    grouped = split(examples, 'filename')\n",
        "\n",
        "    for group in grouped:\n",
        "        tf_example = create_tf_example(group, path)\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "\n",
        "    writer.close()\n",
        "    output_path = os.path.join(os.getcwd(), FLAGS.output_path)\n",
        "    print('Successfully created the Train TFRecord: {}'.format(output_path))\n",
        "\n",
        "\n",
        "#if __name__ == '__main__':\n",
        "    #tf.compat.v1.run()\n",
        "#    with tf.compat.v1.Session() as sess: sess.run()\n",
        "main(_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j-heHsI0Ub5"
      },
      "source": [
        "# Generate TF record - Run for test\n",
        "%%capture\n",
        "%cd {repo_dir_path}\n",
        "FLAGS.remove_flag_values(FLAGS.flag_values_dict())\n",
        "\n",
        "\"\"\"\n",
        "Usage:\n",
        "# Create train data:\n",
        "python generate_tfrecord.py --label_map=<PATH_TO_LABEL_MAP_FILE> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/\n",
        "train_labels.csv --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/train.record\n",
        "\n",
        "# Create test data:\n",
        "python generate_tfrecord.py --label_map=<PATH_TO_LABEL_MAP_FILE> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/\n",
        "test_labels.csv --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/test.record\n",
        "\"\"\"\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"../../models/research\")\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "flags = tf.compat.v1.app.flags\n",
        "flags.DEFINE_string('f','','')\n",
        "flags.DEFINE_string('csv_input', '', 'Path to the CSV input')\n",
        "flags.DEFINE_string('output_path', '', 'Path to output TFRecord')\n",
        "flags.DEFINE_string('img_path', '', 'Path to images')\n",
        "flags.DEFINE_string('label_map', '', 'Path to label map (.pbtxt) file')\n",
        "\n",
        "# if your image has more labels input them as\n",
        "# flags.DEFINE_string('label0', '', 'Name of class[0] label')\n",
        "# flags.DEFINE_string('label1', '', 'Name of class[1] label')\n",
        "# and so on.\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "def class_text_to_int(row_label):\n",
        "    for label_id, label_name in get_label_info():\n",
        "        if row_label == label_name:\n",
        "            return label_id\n",
        "    return 0\n",
        "\n",
        "\n",
        "def get_label_info():\n",
        "    \"\"\"\n",
        "    Generate label info from label map (.pbtxt) file\n",
        "    :return: id, name\n",
        "    \"\"\"\n",
        "    label_info = []\n",
        "    with open(FLAGS.label_map) as fp:\n",
        "        for _, line in enumerate(fp):\n",
        "            if \"id:\" in line:\n",
        "                label_id = int(line.split(\":\")[1])\n",
        "                label_info.append(label_id)\n",
        "            elif \"name:\" in line:\n",
        "                label_name = line.split(\":\")[1].strip().replace(\"'\", \"\")\n",
        "                label_info.append(label_name)\n",
        "\n",
        "    for i in range(0, len(label_info), 2):\n",
        "        yield label_info[i:i + 2]\n",
        "\n",
        "\n",
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    width, height = image.size\n",
        "    filename = group.filename.encode('utf8')\n",
        "    image_format = b'jpg'\n",
        "\n",
        "    # check if the image format is matching with your images.\n",
        "    xmins = []\n",
        "    xmaxs = []\n",
        "    ymins = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for index, row in group.object.iterrows():\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(row['class'].encode('utf8'))\n",
        "        classes.append(class_text_to_int(row['class']))\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "\n",
        "def main(_):\n",
        "    FLAGS.output_path=\"/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord\"\n",
        "    FLAGS.csv_input=\"/content/tensorflow-object-detection-faster-rcnn/data/annotations/test_labels.csv\"\n",
        "    FLAGS.img_path=\"/content/tensorflow-object-detection-faster-rcnn/data/test\"\n",
        "    FLAGS.label_map =\"/content/tensorflow-object-detection-faster-rcnn/data/test/label_map.pbtxt\"\n",
        "    \n",
        "    writer = tf.io.TFRecordWriter(\"/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord\")\n",
        "    path = os.path.join(os.getcwd(), FLAGS.img_path)\n",
        "    examples = pd.read_csv(FLAGS.csv_input)\n",
        "    grouped = split(examples, 'filename')\n",
        "\n",
        "    for group in grouped:\n",
        "        tf_example = create_tf_example(group, path)\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "\n",
        "    writer.close()\n",
        "    output_path = os.path.join(os.getcwd(), FLAGS.output_path)\n",
        "    print('Successfully created the Test TFRecord: {}'.format(output_path))\n",
        "\n",
        "\n",
        "#if __name__ == '__main__':\n",
        "    #tf.compat.v1.run()\n",
        "#    with tf.compat.v1.Session() as sess: sess.run()\n",
        "main(_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEKOjMejmm9U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa99ba11-cd30-4db3-c8c7-6ae37c9a2f1c"
      },
      "source": [
        "# train set\n",
        "%ls /content/tensorflow-object-detection-faster-rcnn/data/train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clear_plastic_bottle10_jpg.rf.94e003f8976d8ab19a4bf6e9c1357a14.jpg\n",
            "clear_plastic_bottle10_jpg.rf.94e003f8976d8ab19a4bf6e9c1357a14.xml\n",
            "clear_plastic_bottle11_jpg.rf.5aea207a1525a5d0bc153f5b85becc2d.jpg\n",
            "clear_plastic_bottle11_jpg.rf.5aea207a1525a5d0bc153f5b85becc2d.xml\n",
            "clear_plastic_bottle12_jpg.rf.7e2c63fd733f0c7c921a73dee3e0ef9f.jpg\n",
            "clear_plastic_bottle12_jpg.rf.7e2c63fd733f0c7c921a73dee3e0ef9f.xml\n",
            "clear_plastic_bottle13_jpg.rf.963d81fb784379c858201fbf7e7c50d3.jpg\n",
            "clear_plastic_bottle13_jpg.rf.963d81fb784379c858201fbf7e7c50d3.xml\n",
            "clear_plastic_bottle14_jpg.rf.24ff1aa17b40c9e3d9591a725fbeb723.jpg\n",
            "clear_plastic_bottle14_jpg.rf.24ff1aa17b40c9e3d9591a725fbeb723.xml\n",
            "clear_plastic_bottle15_jpg.rf.e589c91757fe0179107caaa4ed080710.jpg\n",
            "clear_plastic_bottle15_jpg.rf.e589c91757fe0179107caaa4ed080710.xml\n",
            "clear_plastic_bottle16_jpg.rf.db349d18ca6cf33a75b03f7d70099603.jpg\n",
            "clear_plastic_bottle16_jpg.rf.db349d18ca6cf33a75b03f7d70099603.xml\n",
            "clear_plastic_bottle17_jpg.rf.53877d2c50116a6b67671130071b1854.jpg\n",
            "clear_plastic_bottle17_jpg.rf.53877d2c50116a6b67671130071b1854.xml\n",
            "clear_plastic_bottle18_jpg.rf.280ee97482e8fafb56be0c3b4557cd75.jpg\n",
            "clear_plastic_bottle18_jpg.rf.280ee97482e8fafb56be0c3b4557cd75.xml\n",
            "clear_plastic_bottle19_jpg.rf.b3efe2cba4da50c9a1f6cea40355bec3.jpg\n",
            "clear_plastic_bottle19_jpg.rf.b3efe2cba4da50c9a1f6cea40355bec3.xml\n",
            "clear_plastic_bottle1_jpg.rf.701ea564d2a9dd5cdd1c56c239bda73e.jpg\n",
            "clear_plastic_bottle1_jpg.rf.701ea564d2a9dd5cdd1c56c239bda73e.xml\n",
            "clear_plastic_bottle20_jpg.rf.33def72ae65d654f05d607c44e02c5a8.jpg\n",
            "clear_plastic_bottle20_jpg.rf.33def72ae65d654f05d607c44e02c5a8.xml\n",
            "clear_plastic_bottle21_jpg.rf.183e836b6f3d0cf472b717dcf6f2f714.jpg\n",
            "clear_plastic_bottle21_jpg.rf.183e836b6f3d0cf472b717dcf6f2f714.xml\n",
            "clear_plastic_bottle22_jpg.rf.cc2e3cec0f69c643fad3a7ff01f72b90.jpg\n",
            "clear_plastic_bottle22_jpg.rf.cc2e3cec0f69c643fad3a7ff01f72b90.xml\n",
            "clear_plastic_bottle23_jpg.rf.dba42429a65d16e89b323acc04836525.jpg\n",
            "clear_plastic_bottle23_jpg.rf.dba42429a65d16e89b323acc04836525.xml\n",
            "clear_plastic_bottle24_jpeg.rf.efe40d6c1a75e05252ab71c56b04ab02.jpg\n",
            "clear_plastic_bottle24_jpeg.rf.efe40d6c1a75e05252ab71c56b04ab02.xml\n",
            "clear_plastic_bottle25_jpeg.rf.813e358c8b402fd9c0f53ed8170a50a8.jpg\n",
            "clear_plastic_bottle25_jpeg.rf.813e358c8b402fd9c0f53ed8170a50a8.xml\n",
            "clear_plastic_bottle26_jpeg.rf.f0c8f925f4b2d2d1a1a3362864057684.jpg\n",
            "clear_plastic_bottle26_jpeg.rf.f0c8f925f4b2d2d1a1a3362864057684.xml\n",
            "clear_plastic_bottle27_jpeg.rf.7e420bac512c4099b094679d439130b3.jpg\n",
            "clear_plastic_bottle27_jpeg.rf.7e420bac512c4099b094679d439130b3.xml\n",
            "clear_plastic_bottle2_jpg.rf.3462005e2d30a1dea21ef7bc25251698.jpg\n",
            "clear_plastic_bottle2_jpg.rf.3462005e2d30a1dea21ef7bc25251698.xml\n",
            "clear_plastic_bottle3_jpg.rf.e9b0f8a688cf17944ad67bf545a4f4cc.jpg\n",
            "clear_plastic_bottle3_jpg.rf.e9b0f8a688cf17944ad67bf545a4f4cc.xml\n",
            "clear_plastic_bottle4_jpg.rf.59fd1127fa15b03038a1c8c38d3e47ff.jpg\n",
            "clear_plastic_bottle4_jpg.rf.59fd1127fa15b03038a1c8c38d3e47ff.xml\n",
            "clear_plastic_bottle5_jpg.rf.bd309b6f04c598057128b2bacccb4d52.jpg\n",
            "clear_plastic_bottle5_jpg.rf.bd309b6f04c598057128b2bacccb4d52.xml\n",
            "clear_plastic_bottle6_jpg.rf.2b01e177e8245d618d92b9c3d9d38dca.jpg\n",
            "clear_plastic_bottle6_jpg.rf.2b01e177e8245d618d92b9c3d9d38dca.xml\n",
            "clear_plastic_bottle7_jpg.rf.3aa7bc41fb768449e65b5bf466bbb07c.jpg\n",
            "clear_plastic_bottle7_jpg.rf.3aa7bc41fb768449e65b5bf466bbb07c.xml\n",
            "clear_plastic_bottle8_jpg.rf.a31c4feaa0c9dc68c06070c5b6a13121.jpg\n",
            "clear_plastic_bottle8_jpg.rf.a31c4feaa0c9dc68c06070c5b6a13121.xml\n",
            "clear_plastic_bottle9_jpg.rf.7160f302cef3410f311f5096d552885a.jpg\n",
            "clear_plastic_bottle9_jpg.rf.7160f302cef3410f311f5096d552885a.xml\n",
            "disposable_plastic_cup10_jpeg.rf.a9a89506f4fde3ae33b6c3fcf4810376.jpg\n",
            "disposable_plastic_cup10_jpeg.rf.a9a89506f4fde3ae33b6c3fcf4810376.xml\n",
            "disposable_plastic_cup11_jpeg.rf.7f4e2ce7748032e34e4cd33dc707f7c0.jpg\n",
            "disposable_plastic_cup11_jpeg.rf.7f4e2ce7748032e34e4cd33dc707f7c0.xml\n",
            "disposable_plastic_cup12_jpg.rf.1599390555440b2952f18c784c63eb6d.jpg\n",
            "disposable_plastic_cup12_jpg.rf.1599390555440b2952f18c784c63eb6d.xml\n",
            "disposable_plastic_cup13_jpeg.rf.8a73dc23062d8c2431401f70b87ad401.jpg\n",
            "disposable_plastic_cup13_jpeg.rf.8a73dc23062d8c2431401f70b87ad401.xml\n",
            "disposable_plastic_cup14_jpeg.rf.14ae63c5a5901719f7774bd44fcc7e28.jpg\n",
            "disposable_plastic_cup14_jpeg.rf.14ae63c5a5901719f7774bd44fcc7e28.xml\n",
            "disposable_plastic_cup15_jpeg.rf.f204c9eeda76fdd24143255b008d8427.jpg\n",
            "disposable_plastic_cup15_jpeg.rf.f204c9eeda76fdd24143255b008d8427.xml\n",
            "disposable_plastic_cup16_jpeg.rf.939eee2f062e3f42e221b369c9be48f3.jpg\n",
            "disposable_plastic_cup16_jpeg.rf.939eee2f062e3f42e221b369c9be48f3.xml\n",
            "disposable_plastic_cup17_jpeg.rf.df543dc854bb83443e4001dfa360e02a.jpg\n",
            "disposable_plastic_cup17_jpeg.rf.df543dc854bb83443e4001dfa360e02a.xml\n",
            "disposable_plastic_cup18_jpeg.rf.e124eebc9d17e7acca006c6fedbb9034.jpg\n",
            "disposable_plastic_cup18_jpeg.rf.e124eebc9d17e7acca006c6fedbb9034.xml\n",
            "disposable_plastic_cup19_jpeg.rf.81b9eb168479c01fa87455e583e4c49d.jpg\n",
            "disposable_plastic_cup19_jpeg.rf.81b9eb168479c01fa87455e583e4c49d.xml\n",
            "disposable_plastic_cup1_jpg.rf.816d7642f4264fde77d83d50416d6ebc.jpg\n",
            "disposable_plastic_cup1_jpg.rf.816d7642f4264fde77d83d50416d6ebc.xml\n",
            "disposable_plastic_cup20_jpeg.rf.731a1178170b21989f053e8282017215.jpg\n",
            "disposable_plastic_cup20_jpeg.rf.731a1178170b21989f053e8282017215.xml\n",
            "disposable_plastic_cup21_jpeg.rf.ebbd63bf9a0928afe03ebdce1c6544c2.jpg\n",
            "disposable_plastic_cup21_jpeg.rf.ebbd63bf9a0928afe03ebdce1c6544c2.xml\n",
            "disposable_plastic_cup2_jpg.rf.810467b7d994d59c83bbe015c6c9b6ef.jpg\n",
            "disposable_plastic_cup2_jpg.rf.810467b7d994d59c83bbe015c6c9b6ef.xml\n",
            "disposable_plastic_cup3_jpg.rf.841e42c45e556943d9b7d0b0678ba45e.jpg\n",
            "disposable_plastic_cup3_jpg.rf.841e42c45e556943d9b7d0b0678ba45e.xml\n",
            "disposable_plastic_cup4_jpg.rf.c98c3624b8465bcbeeffda4ba2297594.jpg\n",
            "disposable_plastic_cup4_jpg.rf.c98c3624b8465bcbeeffda4ba2297594.xml\n",
            "disposable_plastic_cup5_jpeg.rf.a45c01d79fc43cca6da92db90b1ff925.jpg\n",
            "disposable_plastic_cup5_jpeg.rf.a45c01d79fc43cca6da92db90b1ff925.xml\n",
            "disposable_plastic_cup6_jpeg.rf.1de80883207a5eb67f1446e92019db0d.jpg\n",
            "disposable_plastic_cup6_jpeg.rf.1de80883207a5eb67f1446e92019db0d.xml\n",
            "disposable_plastic_cup7_jpeg.rf.500c5f5e6186cff0f28e0a4ac696673a.jpg\n",
            "disposable_plastic_cup7_jpeg.rf.500c5f5e6186cff0f28e0a4ac696673a.xml\n",
            "disposable_plastic_cup8_jpeg.rf.cd09f8f99cf083b979500b1171fbf2dd.jpg\n",
            "disposable_plastic_cup8_jpeg.rf.cd09f8f99cf083b979500b1171fbf2dd.xml\n",
            "disposable_plastic_cup9_jpeg.rf.b72482de80ff9829d5f630bf44e912f6.jpg\n",
            "disposable_plastic_cup9_jpeg.rf.b72482de80ff9829d5f630bf44e912f6.xml\n",
            "drink_can10_jpg.rf.6b900bc75f147f86612d5e420f73ca56.jpg\n",
            "drink_can10_jpg.rf.6b900bc75f147f86612d5e420f73ca56.xml\n",
            "drink_can11_jpeg.rf.b5e0463ae8b03bed92abbb07e4a533d5.jpg\n",
            "drink_can11_jpeg.rf.b5e0463ae8b03bed92abbb07e4a533d5.xml\n",
            "drink_can12_jpeg.rf.aca2af7dadb47e4e0a7f35c54220e983.jpg\n",
            "drink_can12_jpeg.rf.aca2af7dadb47e4e0a7f35c54220e983.xml\n",
            "drink_can13_jpg.rf.11703c7feb6f756273f4ea707b8a3aca.jpg\n",
            "drink_can13_jpg.rf.11703c7feb6f756273f4ea707b8a3aca.xml\n",
            "drink_can14_jpg.rf.1c59e29e43e458c1136d04a6c575a4e7.jpg\n",
            "drink_can14_jpg.rf.1c59e29e43e458c1136d04a6c575a4e7.xml\n",
            "drink_can15_jpg.rf.23836041d7fe41ab166b314afae0e655.jpg\n",
            "drink_can15_jpg.rf.23836041d7fe41ab166b314afae0e655.xml\n",
            "drink_can16_jpeg.rf.ffdc9cdedc2d7d3787ddae8f29536f2e.jpg\n",
            "drink_can16_jpeg.rf.ffdc9cdedc2d7d3787ddae8f29536f2e.xml\n",
            "drink_can17_jpg.rf.6409d16affc79a9370f0867c148f2908.jpg\n",
            "drink_can17_jpg.rf.6409d16affc79a9370f0867c148f2908.xml\n",
            "drink_can18_jpg.rf.e8eb14e911cdad2eb7f0f641996f0385.jpg\n",
            "drink_can18_jpg.rf.e8eb14e911cdad2eb7f0f641996f0385.xml\n",
            "drink_can19_jpg.rf.37bec0641dd26ae4c020fca203588996.jpg\n",
            "drink_can19_jpg.rf.37bec0641dd26ae4c020fca203588996.xml\n",
            "drink_can1_jpg.rf.5147a79c48d3b160605cfe551bfc0ad9.jpg\n",
            "drink_can1_jpg.rf.5147a79c48d3b160605cfe551bfc0ad9.xml\n",
            "drink_can20_jpeg.rf.575319eaef9d356a70c642961b8da9b0.jpg\n",
            "drink_can20_jpeg.rf.575319eaef9d356a70c642961b8da9b0.xml\n",
            "drink_can21_jpg.rf.a2f71883e1dcf73baf1d3003c43016a7.jpg\n",
            "drink_can21_jpg.rf.a2f71883e1dcf73baf1d3003c43016a7.xml\n",
            "drink_can2_jpg.rf.ae0ce94d9fc47c77daa5bae32ab92b2f.jpg\n",
            "drink_can2_jpg.rf.ae0ce94d9fc47c77daa5bae32ab92b2f.xml\n",
            "drink_can3_jpg.rf.f0b5b7f391f75c508a34545c5f0e4464.jpg\n",
            "drink_can3_jpg.rf.f0b5b7f391f75c508a34545c5f0e4464.xml\n",
            "drink_can4_jpg.rf.44ab3e63e958be7ff2ac69ad942d2fbc.jpg\n",
            "drink_can4_jpg.rf.44ab3e63e958be7ff2ac69ad942d2fbc.xml\n",
            "drink_can5_jpg.rf.818dfe3bf9a9f7f75e576573eb557afc.jpg\n",
            "drink_can5_jpg.rf.818dfe3bf9a9f7f75e576573eb557afc.xml\n",
            "drink_can6_jpg.rf.c3920307aff7821d6448f6a8c61860f7.jpg\n",
            "drink_can6_jpg.rf.c3920307aff7821d6448f6a8c61860f7.xml\n",
            "drink_can7_jpg.rf.4037d5573fccdc1a142cc28bd7c9d488.jpg\n",
            "drink_can7_jpg.rf.4037d5573fccdc1a142cc28bd7c9d488.xml\n",
            "drink_can8_jpg.rf.13618e8f955864d13100c89fcd0463e0.jpg\n",
            "drink_can8_jpg.rf.13618e8f955864d13100c89fcd0463e0.xml\n",
            "drink_can9_jpg.rf.cc0b8952520a850a77f427714dcc3fe8.jpg\n",
            "drink_can9_jpg.rf.cc0b8952520a850a77f427714dcc3fe8.xml\n",
            "label_map.pbtxt\n",
            "train.tfrecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgd-fzAIkZlV"
      },
      "source": [
        "test_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord'\n",
        "train_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/train.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8"
      },
      "source": [
        "## Download base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDCj6ihgUMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d710b61-036b-4a0b-8082-f396e2403990"
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGhvAObeiIix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01cb7d36-b77f-43e9-e720-918cd3a4dad3"
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 111M\n",
            "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 .\n",
            "drwxr-xr-x 23 root   root 4.0K Mar 29 21:52 ..\n",
            "-rw-r--r--  1 345018 5000   77 Feb  1  2018 checkpoint\n",
            "-rw-r--r--  1 345018 5000  55M Feb  1  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 5000  51M Feb  1  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 5000  16K Feb  1  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 5000 5.5M Feb  1  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 5000 3.2K Feb  1  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHnxlfRznPP3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8af2b87f-445e-48ff-f727-e1e87b04df06"
      },
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD"
      },
      "source": [
        "## Configuring a Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIhw7IdpLuiU"
      },
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG1nCNpUXcRU"
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtCbLF2i0wI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44363b4b-4ed8-4438-b440-af13b32e9d79"
      },
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0MEEanocn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35e3bcdc-10e7-49f6-9b97-f4ae6ed156e4"
      },
      "source": [
        "!cat {pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Faster R-CNN with Inception v2, configured for Oxford-IIIT Pets Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  faster_rcnn {\n",
            "    num_classes: 3\n",
            "    image_resizer {\n",
            "      keep_aspect_ratio_resizer {\n",
            "        min_dimension: 600\n",
            "        max_dimension: 1024\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'faster_rcnn_inception_v2'\n",
            "      first_stage_features_stride: 16\n",
            "    }\n",
            "    first_stage_anchor_generator {\n",
            "      grid_anchor_generator {\n",
            "        scales: [0.25, 0.5, 1.0, 2.0]\n",
            "        aspect_ratios: [0.5, 1.0, 2.0]\n",
            "        height_stride: 16\n",
            "        width_stride: 16\n",
            "      }\n",
            "    }\n",
            "    first_stage_box_predictor_conv_hyperparams {\n",
            "      op: CONV\n",
            "      regularizer {\n",
            "        l2_regularizer {\n",
            "          weight: 0.0\n",
            "        }\n",
            "      }\n",
            "      initializer {\n",
            "        truncated_normal_initializer {\n",
            "          stddev: 0.01\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    first_stage_nms_score_threshold: 0.0\n",
            "    first_stage_nms_iou_threshold: 0.7\n",
            "    first_stage_max_proposals: 300\n",
            "    first_stage_localization_loss_weight: 2.0\n",
            "    first_stage_objectness_loss_weight: 1.0\n",
            "    initial_crop_size: 14\n",
            "    maxpool_kernel_size: 2\n",
            "    maxpool_stride: 2\n",
            "    second_stage_box_predictor {\n",
            "      mask_rcnn_box_predictor {\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 1.0\n",
            "        fc_hyperparams {\n",
            "          op: FC\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.0\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            variance_scaling_initializer {\n",
            "              factor: 1.0\n",
            "              uniform: true\n",
            "              mode: FAN_AVG\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    second_stage_post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 0.0\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 300\n",
            "      }\n",
            "      score_converter: SOFTMAX\n",
            "    }\n",
            "    second_stage_localization_loss_weight: 2.0\n",
            "    second_stage_classification_loss_weight: 1.0\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 12\n",
            "  optimizer {\n",
            "    momentum_optimizer: {\n",
            "      learning_rate: {\n",
            "        manual_step_learning_rate {\n",
            "          initial_learning_rate: 0.0002\n",
            "          schedule {\n",
            "            step: 900000\n",
            "            learning_rate: .00002\n",
            "          }\n",
            "          schedule {\n",
            "            step: 1200000\n",
            "            learning_rate: .000002\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  gradient_clipping_by_norm: 10.0\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  from_detection_checkpoint: true\n",
            "  load_all_detection_checkpoint_vars: true\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 40000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/train.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  num_examples: 1101\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11w0uO3jFCB"
      },
      "source": [
        "#model_dir = 'training/'\n",
        "model_dir = '/content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "#!rm -rf {model_dir}\n",
        "#os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23TECXvNezIF"
      },
      "source": [
        "## Run Tensorboard(Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H2PZs-mSCmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88090a70-e181-4ce6-8569-a6767300e4da"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-29 21:53:27--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.159.163.191, 34.196.3.7, 107.21.11.91, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.159.163.191|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14746350 (14M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  14.06M  18.3MB/s    in 0.8s    \n",
            "\n",
            "2021-03-29 21:53:29 (18.3 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [14746350/14746350]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8o6r1o5SC5M"
      },
      "source": [
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge1OX7gcSC7S"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5GSGxZNh8rp"
      },
      "source": [
        "### Get Tensorboard link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjhPT9iPSJ6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e181b29e-1a79-4a4e-c3a9-5e463661bb91"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://34660baf7ba6.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjDHjhKQofT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea2d5a0-d43f-48a5-d2e7-6911e73268dc"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps=10000 \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0329 23:15:23.140586 140425364469632 model_lib.py:813] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 10000\n",
            "I0329 23:15:23.140835 140425364469632 config_util.py:552] Maybe overwriting train_steps: 10000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0329 23:15:23.141000 140425364469632 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0329 23:15:23.141162 140425364469632 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0329 23:15:23.141336 140425364469632 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0329 23:15:23.141493 140425364469632 model_lib.py:829] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I0329 23:15:23.141662 140425364469632 model_lib.py:866] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb6d42b94d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0329 23:15:23.142297 140425364469632 estimator.py:212] Using config: {'_model_dir': '/content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb6d42b94d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fb6d42aa9e0>) includes params argument, but params are not passed to Estimator.\n",
            "W0329 23:15:23.142556 140425364469632 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fb6d42aa9e0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0329 23:15:23.143096 140425364469632 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0329 23:15:23.143325 140425364469632 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0329 23:15:23.143612 140425364469632 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0329 23:15:23.163454 140425364469632 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/train/train.tfrecord']\n",
            "I0329 23:15:23.191097 140425364469632 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/train/train.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/train/train.tfrecord']\n",
            "I0329 23:15:23.192581 140425364469632 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/train/train.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0329 23:15:23.192775 140425364469632 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0329 23:15:23.192915 140425364469632 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0329 23:15:23.198589 140425364469632 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0329 23:15:23.226070 140425364469632 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:110: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0329 23:15:37.106260 140425364469632 deprecation.py:323] From /content/models/research/object_detection/inputs.py:110: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:94: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0329 23:15:37.307596 140425364469632 deprecation.py:323] From /content/models/research/object_detection/inputs.py:94: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0329 23:15:43.778295 140425364469632 deprecation.py:323] From /content/models/research/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0329 23:15:49.533378 140425364469632 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0329 23:15:49.787934 140425364469632 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0329 23:15:51.445345 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0329 23:15:51.618489 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 23:15:51.618937 140425364469632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0329 23:15:59.862429 140425364469632 deprecation.py:506] From /content/models/research/object_detection/utils/spatial_transform_ops.py:478: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0329 23:16:00.537070 140425364469632 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0329 23:16:00.539957 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0329 23:16:00.560190 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:453: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0329 23:16:04.007422 140425364469632 deprecation.py:323] From /content/models/research/object_detection/core/losses.py:453: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0329 23:16:13.174332 140425364469632 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0329 23:16:13.175978 140425364469632 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0329 23:16:17.641644 140425364469632 monitored_session.py:240] Graph was finalized.\n",
            "2021-03-29 23:16:17.647065: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-03-29 23:16:17.647341: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558ae194aa00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-03-29 23:16:17.647375: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-03-29 23:16:17.649360: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-03-29 23:16:17.766109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:16:17.767193: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558ae194a680 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-03-29 23:16:17.767249: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2021-03-29 23:16:17.767477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:16:17.768419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-29 23:16:17.768789: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-03-29 23:16:17.770583: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-03-29 23:16:17.772427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-03-29 23:16:17.772805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-03-29 23:16:17.774609: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-03-29 23:16:17.775513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-03-29 23:16:17.779324: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-29 23:16:17.779455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:16:17.780413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:16:17.781321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-03-29 23:16:17.781418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-03-29 23:16:17.783322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-29 23:16:17.783365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-03-29 23:16:17.783382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-03-29 23:16:17.783517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:16:17.784484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:16:17.785339: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-03-29 23:16:17.785392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-6008\n",
            "I0329 23:16:17.791064 140425364469632 saver.py:1284] Restoring parameters from /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-6008\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "W0329 23:16:19.965280 140425364469632 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0329 23:16:20.934395 140425364469632 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0329 23:16:21.407862 140425364469632 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 6008 into /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt.\n",
            "I0329 23:16:35.308813 140425364469632 basic_session_run_hooks.py:606] Saving checkpoints for 6008 into /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt.\n",
            "2021-03-29 23:16:47.555507: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-03-29 23:16:49.292467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "INFO:tensorflow:loss = 0.32699677, step = 6008\n",
            "I0329 23:16:53.622831 140425364469632 basic_session_run_hooks.py:262] loss = 0.32699677, step = 6008\n",
            "INFO:tensorflow:global_step/sec: 1.28904\n",
            "I0329 23:18:11.199423 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.28904\n",
            "INFO:tensorflow:loss = 0.3149981, step = 6108 (77.578 sec)\n",
            "I0329 23:18:11.200660 140425364469632 basic_session_run_hooks.py:260] loss = 0.3149981, step = 6108 (77.578 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43838\n",
            "I0329 23:19:20.722285 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43838\n",
            "INFO:tensorflow:loss = 0.27572885, step = 6208 (69.523 sec)\n",
            "I0329 23:19:20.723875 140425364469632 basic_session_run_hooks.py:260] loss = 0.27572885, step = 6208 (69.523 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43921\n",
            "I0329 23:20:30.204796 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43921\n",
            "INFO:tensorflow:loss = 0.23736797, step = 6308 (69.482 sec)\n",
            "I0329 23:20:30.205931 140425364469632 basic_session_run_hooks.py:260] loss = 0.23736797, step = 6308 (69.482 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43579\n",
            "I0329 23:21:39.852819 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43579\n",
            "INFO:tensorflow:loss = 0.28607228, step = 6408 (69.648 sec)\n",
            "I0329 23:21:39.854361 140425364469632 basic_session_run_hooks.py:260] loss = 0.28607228, step = 6408 (69.648 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.44041\n",
            "I0329 23:22:49.277551 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.44041\n",
            "INFO:tensorflow:loss = 0.22177714, step = 6508 (69.425 sec)\n",
            "I0329 23:22:49.278853 140425364469632 basic_session_run_hooks.py:260] loss = 0.22177714, step = 6508 (69.425 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.44147\n",
            "I0329 23:23:58.651363 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.44147\n",
            "INFO:tensorflow:loss = 0.2802443, step = 6608 (69.374 sec)\n",
            "I0329 23:23:58.653126 140425364469632 basic_session_run_hooks.py:260] loss = 0.2802443, step = 6608 (69.374 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43456\n",
            "I0329 23:25:08.359078 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43456\n",
            "INFO:tensorflow:loss = 0.24045582, step = 6708 (69.707 sec)\n",
            "I0329 23:25:08.360178 140425364469632 basic_session_run_hooks.py:260] loss = 0.24045582, step = 6708 (69.707 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.4449\n",
            "I0329 23:26:17.567813 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.4449\n",
            "INFO:tensorflow:loss = 0.25219882, step = 6808 (69.209 sec)\n",
            "I0329 23:26:17.569327 140425364469632 basic_session_run_hooks.py:260] loss = 0.25219882, step = 6808 (69.209 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 6840 into /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt.\n",
            "I0329 23:26:38.968195 140425364469632 basic_session_run_hooks.py:606] Saving checkpoints for 6840 into /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0329 23:26:39.711543 140425364469632 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "I0329 23:26:41.685659 140425364469632 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "I0329 23:26:41.686224 140425364469632 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0329 23:26:41.686433 140425364469632 dataset_builder.py:81] Number of filenames to read: 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0329 23:26:42.943858 140425364469632 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0329 23:26:44.617435 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0329 23:26:44.787607 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 23:26:44.788052 140425364469632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0329 23:26:45.990602 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0329 23:26:46.009988 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "W0329 23:26:46.576188 140425364469632 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0329 23:26:47.274749 140425364469632 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0329 23:26:47.530894 140425364469632 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0329 23:26:48.217151 140425364469632 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-03-29T23:26:48Z\n",
            "I0329 23:26:48.237458 140425364469632 evaluation.py:255] Starting evaluation at 2021-03-29T23:26:48Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0329 23:26:48.817653 140425364469632 monitored_session.py:240] Graph was finalized.\n",
            "2021-03-29 23:26:48.819347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:26:48.819806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-29 23:26:48.819967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-03-29 23:26:48.820039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-03-29 23:26:48.820099: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-03-29 23:26:48.820152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-03-29 23:26:48.820202: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-03-29 23:26:48.820245: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-03-29 23:26:48.820289: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-29 23:26:48.820386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:26:48.820870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:26:48.821480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-03-29 23:26:48.821534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-29 23:26:48.821558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-03-29 23:26:48.821577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-03-29 23:26:48.821694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:26:48.822215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:26:48.822617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-6840\n",
            "I0329 23:26:48.825532 140425364469632 saver.py:1284] Restoring parameters from /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-6840\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0329 23:26:50.293022 140425364469632 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0329 23:26:50.435839 140425364469632 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 0 images.\n",
            "I0329 23:26:52.773753 140421200238336 coco_evaluation.py:293] Performing evaluation on 0 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0329 23:26:52.774393 140421200238336 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0329 23:26:52.774601 140421200238336 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.00s).\n",
            "Accumulating evaluation results...\n",
            "Please run evaluate() first\n",
            "DONE (t=0.00s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2021-03-29-23:26:52\n",
            "I0329 23:26:52.871490 140425364469632 evaluation.py:275] Finished evaluation at 2021-03-29-23:26:52\n",
            "INFO:tensorflow:Saving dict for global step 6840: DetectionBoxes_Precision/mAP = -1.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = -1.0, DetectionBoxes_Precision/mAP@.75IOU = -1.0, DetectionBoxes_Recall/AR@1 = -1.0, DetectionBoxes_Recall/AR@10 = -1.0, DetectionBoxes_Recall/AR@100 = -1.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.0, Loss/BoxClassifierLoss/localization_loss = 0.0, Loss/RPNLoss/localization_loss = 0.0, Loss/RPNLoss/objectness_loss = 0.0, Loss/total_loss = 0.0, global_step = 6840, learning_rate = 0.0002, loss = 0.0\n",
            "I0329 23:26:52.871860 140425364469632 estimator.py:2049] Saving dict for global step 6840: DetectionBoxes_Precision/mAP = -1.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = -1.0, DetectionBoxes_Precision/mAP@.75IOU = -1.0, DetectionBoxes_Recall/AR@1 = -1.0, DetectionBoxes_Recall/AR@10 = -1.0, DetectionBoxes_Recall/AR@100 = -1.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.0, Loss/BoxClassifierLoss/localization_loss = 0.0, Loss/RPNLoss/localization_loss = 0.0, Loss/RPNLoss/objectness_loss = 0.0, Loss/total_loss = 0.0, global_step = 6840, learning_rate = 0.0002, loss = 0.0\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6840: /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-6840\n",
            "I0329 23:26:54.121196 140425364469632 estimator.py:2109] Saving 'checkpoint_path' summary for global step 6840: /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-6840\n",
            "INFO:tensorflow:global_step/sec: 1.18467\n",
            "I0329 23:27:41.979464 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.18467\n",
            "INFO:tensorflow:loss = 0.31880748, step = 6908 (84.411 sec)\n",
            "I0329 23:27:41.980627 140425364469632 basic_session_run_hooks.py:260] loss = 0.31880748, step = 6908 (84.411 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.44566\n",
            "I0329 23:28:51.151781 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.44566\n",
            "INFO:tensorflow:loss = 0.2997662, step = 7008 (69.173 sec)\n",
            "I0329 23:28:51.153823 140425364469632 basic_session_run_hooks.py:260] loss = 0.2997662, step = 7008 (69.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.4498\n",
            "I0329 23:30:00.126959 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.4498\n",
            "INFO:tensorflow:loss = 0.28364754, step = 7108 (68.974 sec)\n",
            "I0329 23:30:00.128303 140425364469632 basic_session_run_hooks.py:260] loss = 0.28364754, step = 7108 (68.974 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43673\n",
            "I0329 23:31:09.729439 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43673\n",
            "INFO:tensorflow:loss = 0.33658507, step = 7208 (69.603 sec)\n",
            "I0329 23:31:09.731238 140425364469632 basic_session_run_hooks.py:260] loss = 0.33658507, step = 7208 (69.603 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.42919\n",
            "I0329 23:32:19.699200 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.42919\n",
            "INFO:tensorflow:loss = 0.27248392, step = 7308 (69.969 sec)\n",
            "I0329 23:32:19.700431 140425364469632 basic_session_run_hooks.py:260] loss = 0.27248392, step = 7308 (69.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43471\n",
            "I0329 23:33:29.399479 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43471\n",
            "INFO:tensorflow:loss = 0.1899482, step = 7408 (69.701 sec)\n",
            "I0329 23:33:29.401287 140425364469632 basic_session_run_hooks.py:260] loss = 0.1899482, step = 7408 (69.701 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43843\n",
            "I0329 23:34:38.919416 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43843\n",
            "INFO:tensorflow:loss = 0.18791586, step = 7508 (69.519 sec)\n",
            "I0329 23:34:38.920669 140425364469632 basic_session_run_hooks.py:260] loss = 0.18791586, step = 7508 (69.519 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43865\n",
            "I0329 23:35:48.428853 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43865\n",
            "INFO:tensorflow:loss = 0.22719005, step = 7608 (69.510 sec)\n",
            "I0329 23:35:48.430204 140425364469632 basic_session_run_hooks.py:260] loss = 0.22719005, step = 7608 (69.510 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 7682 into /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt.\n",
            "I0329 23:36:39.350046 140425364469632 basic_session_run_hooks.py:606] Saving checkpoints for 7682 into /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0329 23:36:41.610339 140425364469632 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 1.38638\n",
            "I0329 23:37:00.558989 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.38638\n",
            "INFO:tensorflow:loss = 0.19709744, step = 7708 (72.130 sec)\n",
            "I0329 23:37:00.560071 140425364469632 basic_session_run_hooks.py:260] loss = 0.19709744, step = 7708 (72.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43927\n",
            "I0329 23:38:10.038537 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43927\n",
            "INFO:tensorflow:loss = 0.17980807, step = 7808 (69.480 sec)\n",
            "I0329 23:38:10.040135 140425364469632 basic_session_run_hooks.py:260] loss = 0.17980807, step = 7808 (69.480 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43606\n",
            "I0329 23:39:19.673711 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43606\n",
            "INFO:tensorflow:loss = 0.23281258, step = 7908 (69.635 sec)\n",
            "I0329 23:39:19.674949 140425364469632 basic_session_run_hooks.py:260] loss = 0.23281258, step = 7908 (69.635 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43831\n",
            "I0329 23:40:29.199910 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43831\n",
            "INFO:tensorflow:loss = 0.28472054, step = 8008 (69.527 sec)\n",
            "I0329 23:40:29.201669 140425364469632 basic_session_run_hooks.py:260] loss = 0.28472054, step = 8008 (69.527 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43385\n",
            "I0329 23:41:38.942236 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43385\n",
            "INFO:tensorflow:loss = 0.29787093, step = 8108 (69.742 sec)\n",
            "I0329 23:41:38.943455 140425364469632 basic_session_run_hooks.py:260] loss = 0.29787093, step = 8108 (69.742 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.439\n",
            "I0329 23:42:48.434662 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.439\n",
            "INFO:tensorflow:loss = 0.1881243, step = 8208 (69.493 sec)\n",
            "I0329 23:42:48.436386 140425364469632 basic_session_run_hooks.py:260] loss = 0.1881243, step = 8208 (69.493 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43289\n",
            "I0329 23:43:58.223470 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43289\n",
            "INFO:tensorflow:loss = 0.23715395, step = 8308 (69.788 sec)\n",
            "I0329 23:43:58.224792 140425364469632 basic_session_run_hooks.py:260] loss = 0.23715395, step = 8308 (69.788 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43592\n",
            "I0329 23:45:07.865421 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43592\n",
            "INFO:tensorflow:loss = 0.23287943, step = 8408 (69.642 sec)\n",
            "I0329 23:45:07.866959 140425364469632 basic_session_run_hooks.py:260] loss = 0.23287943, step = 8408 (69.642 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43657\n",
            "I0329 23:46:17.475579 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43657\n",
            "INFO:tensorflow:loss = 0.26081946, step = 8508 (69.610 sec)\n",
            "I0329 23:46:17.476761 140425364469632 basic_session_run_hooks.py:260] loss = 0.26081946, step = 8508 (69.610 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 8541 into /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt.\n",
            "I0329 23:46:39.689027 140425364469632 basic_session_run_hooks.py:606] Saving checkpoints for 8541 into /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "I0329 23:46:42.256147 140425364469632 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "I0329 23:46:42.259064 140425364469632 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0329 23:46:42.259267 140425364469632 dataset_builder.py:81] Number of filenames to read: 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0329 23:46:43.328021 140425364469632 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0329 23:46:45.029700 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0329 23:46:45.203118 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 23:46:45.203533 140425364469632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0329 23:46:46.475678 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0329 23:46:46.496137 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0329 23:46:48.696009 140425364469632 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-03-29T23:46:48Z\n",
            "I0329 23:46:48.715731 140425364469632 evaluation.py:255] Starting evaluation at 2021-03-29T23:46:48Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0329 23:46:49.276825 140425364469632 monitored_session.py:240] Graph was finalized.\n",
            "2021-03-29 23:46:49.277644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:46:49.278201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-29 23:46:49.278335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-03-29 23:46:49.278393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-03-29 23:46:49.278441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-03-29 23:46:49.278494: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-03-29 23:46:49.278536: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-03-29 23:46:49.278577: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-03-29 23:46:49.278640: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-29 23:46:49.278738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:46:49.279390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:46:49.279801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-03-29 23:46:49.279864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-29 23:46:49.279885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-03-29 23:46:49.279918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-03-29 23:46:49.280035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:46:49.280537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:46:49.280981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-8541\n",
            "I0329 23:46:49.283464 140425364469632 saver.py:1284] Restoring parameters from /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-8541\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0329 23:46:50.665231 140425364469632 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0329 23:46:50.843921 140425364469632 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 0 images.\n",
            "I0329 23:46:53.186150 140421191845632 coco_evaluation.py:293] Performing evaluation on 0 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0329 23:46:53.187681 140421191845632 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0329 23:46:53.187926 140421191845632 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.00s).\n",
            "Accumulating evaluation results...\n",
            "Please run evaluate() first\n",
            "DONE (t=0.00s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2021-03-29-23:46:53\n",
            "I0329 23:46:53.295381 140425364469632 evaluation.py:275] Finished evaluation at 2021-03-29-23:46:53\n",
            "INFO:tensorflow:Saving dict for global step 8541: DetectionBoxes_Precision/mAP = -1.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = -1.0, DetectionBoxes_Precision/mAP@.75IOU = -1.0, DetectionBoxes_Recall/AR@1 = -1.0, DetectionBoxes_Recall/AR@10 = -1.0, DetectionBoxes_Recall/AR@100 = -1.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.0, Loss/BoxClassifierLoss/localization_loss = 0.0, Loss/RPNLoss/localization_loss = 0.0, Loss/RPNLoss/objectness_loss = 0.0, Loss/total_loss = 0.0, global_step = 8541, learning_rate = 0.0002, loss = 0.0\n",
            "I0329 23:46:53.295767 140425364469632 estimator.py:2049] Saving dict for global step 8541: DetectionBoxes_Precision/mAP = -1.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = -1.0, DetectionBoxes_Precision/mAP@.75IOU = -1.0, DetectionBoxes_Recall/AR@1 = -1.0, DetectionBoxes_Recall/AR@10 = -1.0, DetectionBoxes_Recall/AR@100 = -1.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.0, Loss/BoxClassifierLoss/localization_loss = 0.0, Loss/RPNLoss/localization_loss = 0.0, Loss/RPNLoss/objectness_loss = 0.0, Loss/total_loss = 0.0, global_step = 8541, learning_rate = 0.0002, loss = 0.0\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8541: /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-8541\n",
            "I0329 23:46:53.297634 140425364469632 estimator.py:2109] Saving 'checkpoint_path' summary for global step 8541: /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-8541\n",
            "INFO:tensorflow:global_step/sec: 1.20125\n",
            "I0329 23:47:40.722449 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.20125\n",
            "INFO:tensorflow:loss = 0.2437383, step = 8608 (83.247 sec)\n",
            "I0329 23:47:40.724117 140425364469632 basic_session_run_hooks.py:260] loss = 0.2437383, step = 8608 (83.247 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.4381\n",
            "I0329 23:48:50.258852 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.4381\n",
            "INFO:tensorflow:loss = 0.18466608, step = 8708 (69.536 sec)\n",
            "I0329 23:48:50.260193 140425364469632 basic_session_run_hooks.py:260] loss = 0.18466608, step = 8708 (69.536 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43664\n",
            "I0329 23:49:59.865632 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43664\n",
            "INFO:tensorflow:loss = 0.17433533, step = 8808 (69.607 sec)\n",
            "I0329 23:49:59.867447 140425364469632 basic_session_run_hooks.py:260] loss = 0.17433533, step = 8808 (69.607 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.44221\n",
            "I0329 23:51:09.203520 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.44221\n",
            "INFO:tensorflow:loss = 0.28802153, step = 8908 (69.337 sec)\n",
            "I0329 23:51:09.204764 140425364469632 basic_session_run_hooks.py:260] loss = 0.28802153, step = 8908 (69.337 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43621\n",
            "I0329 23:52:18.831491 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43621\n",
            "INFO:tensorflow:loss = 0.20177025, step = 9008 (69.628 sec)\n",
            "I0329 23:52:18.833023 140425364469632 basic_session_run_hooks.py:260] loss = 0.20177025, step = 9008 (69.628 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43715\n",
            "I0329 23:53:28.413338 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43715\n",
            "INFO:tensorflow:loss = 0.23893592, step = 9108 (69.582 sec)\n",
            "I0329 23:53:28.414574 140425364469632 basic_session_run_hooks.py:260] loss = 0.23893592, step = 9108 (69.582 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43789\n",
            "I0329 23:54:37.959877 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43789\n",
            "INFO:tensorflow:loss = 0.2497762, step = 9208 (69.547 sec)\n",
            "I0329 23:54:37.961856 140425364469632 basic_session_run_hooks.py:260] loss = 0.2497762, step = 9208 (69.547 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43712\n",
            "I0329 23:55:47.543511 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43712\n",
            "INFO:tensorflow:loss = 0.26801178, step = 9308 (69.583 sec)\n",
            "I0329 23:55:47.544764 140425364469632 basic_session_run_hooks.py:260] loss = 0.26801178, step = 9308 (69.583 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 9384 into /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt.\n",
            "I0329 23:56:39.833600 140425364469632 basic_session_run_hooks.py:606] Saving checkpoints for 9384 into /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "I0329 23:56:42.473292 140425364469632 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "I0329 23:56:42.473755 140425364469632 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0329 23:56:42.473975 140425364469632 dataset_builder.py:81] Number of filenames to read: 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0329 23:56:43.486386 140425364469632 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0329 23:56:45.153594 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0329 23:56:45.330345 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 23:56:45.330735 140425364469632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0329 23:56:46.620290 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0329 23:56:46.640493 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0329 23:56:49.342379 140425364469632 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-03-29T23:56:49Z\n",
            "I0329 23:56:49.362379 140425364469632 evaluation.py:255] Starting evaluation at 2021-03-29T23:56:49Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0329 23:56:49.969692 140425364469632 monitored_session.py:240] Graph was finalized.\n",
            "2021-03-29 23:56:49.970777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:56:49.971570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-29 23:56:49.971687: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-03-29 23:56:49.971776: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-03-29 23:56:49.971860: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-03-29 23:56:49.971943: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-03-29 23:56:49.971991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-03-29 23:56:49.972043: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-03-29 23:56:49.972095: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-29 23:56:49.972222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:56:49.972796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:56:49.973475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-03-29 23:56:49.973541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-29 23:56:49.973567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-03-29 23:56:49.973585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-03-29 23:56:49.973722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:56:49.974567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 23:56:49.975203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-9384\n",
            "I0329 23:56:49.980513 140425364469632 saver.py:1284] Restoring parameters from /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-9384\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0329 23:56:51.465124 140425364469632 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0329 23:56:51.636426 140425364469632 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 0 images.\n",
            "I0329 23:56:54.025302 140421191845632 coco_evaluation.py:293] Performing evaluation on 0 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0329 23:56:54.025768 140421191845632 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0329 23:56:54.026023 140421191845632 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.00s).\n",
            "Accumulating evaluation results...\n",
            "Please run evaluate() first\n",
            "DONE (t=0.00s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2021-03-29-23:56:54\n",
            "I0329 23:56:54.123324 140425364469632 evaluation.py:275] Finished evaluation at 2021-03-29-23:56:54\n",
            "INFO:tensorflow:Saving dict for global step 9384: DetectionBoxes_Precision/mAP = -1.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = -1.0, DetectionBoxes_Precision/mAP@.75IOU = -1.0, DetectionBoxes_Recall/AR@1 = -1.0, DetectionBoxes_Recall/AR@10 = -1.0, DetectionBoxes_Recall/AR@100 = -1.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.0, Loss/BoxClassifierLoss/localization_loss = 0.0, Loss/RPNLoss/localization_loss = 0.0, Loss/RPNLoss/objectness_loss = 0.0, Loss/total_loss = 0.0, global_step = 9384, learning_rate = 0.0002, loss = 0.0\n",
            "I0329 23:56:54.123671 140425364469632 estimator.py:2049] Saving dict for global step 9384: DetectionBoxes_Precision/mAP = -1.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = -1.0, DetectionBoxes_Precision/mAP@.75IOU = -1.0, DetectionBoxes_Recall/AR@1 = -1.0, DetectionBoxes_Recall/AR@10 = -1.0, DetectionBoxes_Recall/AR@100 = -1.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.0, Loss/BoxClassifierLoss/localization_loss = 0.0, Loss/RPNLoss/localization_loss = 0.0, Loss/RPNLoss/objectness_loss = 0.0, Loss/total_loss = 0.0, global_step = 9384, learning_rate = 0.0002, loss = 0.0\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9384: /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-9384\n",
            "I0329 23:56:54.125115 140425364469632 estimator.py:2109] Saving 'checkpoint_path' summary for global step 9384: /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-9384\n",
            "INFO:tensorflow:global_step/sec: 1.19106\n",
            "I0329 23:57:11.502143 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.19106\n",
            "INFO:tensorflow:loss = 0.14790767, step = 9408 (83.959 sec)\n",
            "I0329 23:57:11.503496 140425364469632 basic_session_run_hooks.py:260] loss = 0.14790767, step = 9408 (83.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.4392\n",
            "I0329 23:58:20.985357 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.4392\n",
            "INFO:tensorflow:loss = 0.1590179, step = 9508 (69.483 sec)\n",
            "I0329 23:58:20.986501 140425364469632 basic_session_run_hooks.py:260] loss = 0.1590179, step = 9508 (69.483 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43693\n",
            "I0329 23:59:30.577838 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43693\n",
            "INFO:tensorflow:loss = 0.1747971, step = 9608 (69.593 sec)\n",
            "I0329 23:59:30.579681 140425364469632 basic_session_run_hooks.py:260] loss = 0.1747971, step = 9608 (69.593 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43636\n",
            "I0330 00:00:40.198116 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43636\n",
            "INFO:tensorflow:loss = 0.16338532, step = 9708 (69.620 sec)\n",
            "I0330 00:00:40.199251 140425364469632 basic_session_run_hooks.py:260] loss = 0.16338532, step = 9708 (69.620 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43982\n",
            "I0330 00:01:49.651332 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43982\n",
            "INFO:tensorflow:loss = 0.16326378, step = 9808 (69.454 sec)\n",
            "I0330 00:01:49.652886 140425364469632 basic_session_run_hooks.py:260] loss = 0.16326378, step = 9808 (69.454 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43625\n",
            "I0330 00:02:59.277266 140425364469632 basic_session_run_hooks.py:692] global_step/sec: 1.43625\n",
            "INFO:tensorflow:loss = 0.19111331, step = 9908 (69.626 sec)\n",
            "I0330 00:02:59.278493 140425364469632 basic_session_run_hooks.py:260] loss = 0.19111331, step = 9908 (69.626 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt.\n",
            "I0330 00:04:02.561311 140425364469632 basic_session_run_hooks.py:606] Saving checkpoints for 10000 into /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0330 00:04:04.878914 140425364469632 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "I0330 00:04:04.907600 140425364469632 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "I0330 00:04:04.908061 140425364469632 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0330 00:04:04.908217 140425364469632 dataset_builder.py:81] Number of filenames to read: 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0330 00:04:05.916986 140425364469632 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0330 00:04:07.603439 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0330 00:04:07.781260 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0330 00:04:07.781758 140425364469632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0330 00:04:09.006809 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0330 00:04:09.027447 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0330 00:04:11.190262 140425364469632 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-03-30T00:04:11Z\n",
            "I0330 00:04:11.210082 140425364469632 evaluation.py:255] Starting evaluation at 2021-03-30T00:04:11Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0330 00:04:11.785305 140425364469632 monitored_session.py:240] Graph was finalized.\n",
            "2021-03-30 00:04:11.786087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-30 00:04:11.786627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-30 00:04:11.786749: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-03-30 00:04:11.786799: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-03-30 00:04:11.786849: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-03-30 00:04:11.786917: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-03-30 00:04:11.786988: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-03-30 00:04:11.787032: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-03-30 00:04:11.787075: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-30 00:04:11.787201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-30 00:04:11.787696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-30 00:04:11.788103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-03-30 00:04:11.788156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-30 00:04:11.788180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-03-30 00:04:11.788196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-03-30 00:04:11.788314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-30 00:04:11.788783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-30 00:04:11.789383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-10000\n",
            "I0330 00:04:11.792002 140425364469632 saver.py:1284] Restoring parameters from /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0330 00:04:13.096786 140425364469632 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0330 00:04:13.259216 140425364469632 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 0 images.\n",
            "I0330 00:04:15.814247 140421200238336 coco_evaluation.py:293] Performing evaluation on 0 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0330 00:04:15.814657 140421200238336 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0330 00:04:15.814926 140421200238336 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.00s).\n",
            "Accumulating evaluation results...\n",
            "Please run evaluate() first\n",
            "DONE (t=0.00s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2021-03-30-00:04:15\n",
            "I0330 00:04:15.912163 140425364469632 evaluation.py:275] Finished evaluation at 2021-03-30-00:04:15\n",
            "INFO:tensorflow:Saving dict for global step 10000: DetectionBoxes_Precision/mAP = -1.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = -1.0, DetectionBoxes_Precision/mAP@.75IOU = -1.0, DetectionBoxes_Recall/AR@1 = -1.0, DetectionBoxes_Recall/AR@10 = -1.0, DetectionBoxes_Recall/AR@100 = -1.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.0, Loss/BoxClassifierLoss/localization_loss = 0.0, Loss/RPNLoss/localization_loss = 0.0, Loss/RPNLoss/objectness_loss = 0.0, Loss/total_loss = 0.0, global_step = 10000, learning_rate = 0.0002, loss = 0.0\n",
            "I0330 00:04:15.912562 140425364469632 estimator.py:2049] Saving dict for global step 10000: DetectionBoxes_Precision/mAP = -1.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = -1.0, DetectionBoxes_Precision/mAP@.75IOU = -1.0, DetectionBoxes_Recall/AR@1 = -1.0, DetectionBoxes_Recall/AR@10 = -1.0, DetectionBoxes_Recall/AR@100 = -1.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.0, Loss/BoxClassifierLoss/localization_loss = 0.0, Loss/RPNLoss/localization_loss = 0.0, Loss/RPNLoss/objectness_loss = 0.0, Loss/total_loss = 0.0, global_step = 10000, learning_rate = 0.0002, loss = 0.0\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-10000\n",
            "I0330 00:04:15.914265 140425364469632 estimator.py:2109] Saving 'checkpoint_path' summary for global step 10000: /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-10000\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I0330 00:04:15.915227 140425364469632 exporter.py:410] Performing the final export in the end of training.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0330 00:04:16.301856 140425364469632 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0330 00:04:17.944838 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0330 00:04:18.126340 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0330 00:04:18.126778 140425364469632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0330 00:04:19.373022 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0330 00:04:19.393427 140425364469632 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0330 00:04:20.869254 140425364469632 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0330 00:04:20.869626 140425364469632 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I0330 00:04:20.870410 140425364469632 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I0330 00:04:20.870562 140425364469632 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I0330 00:04:20.870712 140425364469632 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I0330 00:04:20.870867 140425364469632 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I0330 00:04:20.871007 140425364469632 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2021-03-30 00:04:20.871662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-30 00:04:20.872260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-30 00:04:20.872355: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-03-30 00:04:20.872419: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-03-30 00:04:20.872469: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-03-30 00:04:20.872525: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-03-30 00:04:20.872571: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-03-30 00:04:20.872615: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-03-30 00:04:20.872660: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-30 00:04:20.872760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-30 00:04:20.873313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-30 00:04:20.873726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-03-30 00:04:20.873779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-30 00:04:20.873809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-03-30 00:04:20.873826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-03-30 00:04:20.873960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-30 00:04:20.874430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-30 00:04:20.874856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-10000\n",
            "I0330 00:04:20.879366 140425364469632 saver.py:1284] Restoring parameters from /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/model.ckpt-10000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I0330 00:04:21.519106 140425364469632 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0330 00:04:21.519367 140425364469632 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/export/Servo/temp-b'1617062655'/saved_model.pb\n",
            "I0330 00:04:22.566733 140425364469632 builder_impl.py:425] SavedModel written to: /content/gdrive/MyDrive/Juice_Box/FRCNN/Checkpoints/export/Servo/temp-b'1617062655'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 0.22711752.\n",
            "I0330 00:04:22.980771 140425364469632 estimator.py:371] Loss for final step: 0.22711752.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-tUdtnRybs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5cab777-8164-4718-ee85-5fe971543a7c"
      },
      "source": [
        "!ls {model_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\n",
            "eval_0\n",
            "events.out.tfevents.1617054889.55403818f9f1\n",
            "events.out.tfevents.1617059775.55403818f9f1\n",
            "export\n",
            "graph.pbtxt\n",
            "model.ckpt-10000.data-00000-of-00001\n",
            "model.ckpt-10000.index\n",
            "model.ckpt-10000.meta\n",
            "model.ckpt-6840.data-00000-of-00001\n",
            "model.ckpt-6840.index\n",
            "model.ckpt-6840.meta\n",
            "model.ckpt-7682.data-00000-of-00001\n",
            "model.ckpt-7682.index\n",
            "model.ckpt-7682.meta\n",
            "model.ckpt-8541.data-00000-of-00001\n",
            "model.ckpt-8541.index\n",
            "model.ckpt-8541.meta\n",
            "model.ckpt-9384.data-00000-of-00001\n",
            "model.ckpt-9384.index\n",
            "model.ckpt-9384.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usgBZvkz0nqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "657c8911-eaea-4813-8e7a-0a5228eb0205"
      },
      "source": [
        "!ls {output_directory}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\tmodel.ckpt.index  saved_model\n",
            "frozen_inference_graph.pb\tmodel.ckpt.meta\n",
            "model.ckpt.data-00000-of-00001\tpipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5cabQ1jc6I0E",
        "outputId": "863a492e-fa90-437c-da06-bd10b5c6d320"
      },
      "source": [
        "last_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'model.ckpt-10000'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    }
  ]
}