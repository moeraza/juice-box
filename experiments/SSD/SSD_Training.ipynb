{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SSD_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhzxsJb3dpWq"
      },
      "source": [
        "## Configs and Hyperparameters\n",
        "\n",
        "Supports a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNXNQCjdniL"
      },
      "source": [
        "# If you forked the repo, you can replace the link.\n",
        "repo_url = 'https://github.com/roboflow-ai/tensorflow-object-detection-faster-rcnn'\n",
        "\n",
        "# Number of training steps - 1000 will train very quickly, but more steps will increase accuracy.\n",
        "num_steps = 40000  # 200000 to improve\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    },    \n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'ssd_mobilenet_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colab's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL8oRGC5UgMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c139d80-13ec-4c62-fc8b-336eaa3c3d40"
      },
      "source": [
        "# use TF 1.x for Object Detection APIs as they are not ported to TF 2.0 yet\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(\"You are using TensorFlow version\", tf .__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4V-XE6kbkc1"
      },
      "source": [
        "## Clone the `tensorflow-object-detection` repository or your fork."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxc3DmvLQF3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13c0c480-3953-4415-82a7-0807afd81802"
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'tensorflow-object-detection-faster-rcnn'...\n",
            "remote: Enumerating objects: 885, done.\u001b[K\n",
            "remote: Total 885 (delta 0), reused 0 (delta 0), pack-reused 885\u001b[K\n",
            "Receiving objects: 100% (885/885), 24.83 MiB | 29.88 MiB/s, done.\n",
            "Resolving deltas: 100% (428/428), done.\n",
            "/content/tensorflow-object-detection-faster-rcnn\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI8__uNS8-ns"
      },
      "source": [
        "## Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecpHEnka8Kix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be49c3cb-0a9d-4ef0-c0f6-c36630629bbf"
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!pip install tf_slim\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "!pip install lvis\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 15.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 160980 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.5_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.5) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.5) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting lvis\n",
            "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.3.1)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.2.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis) (4.1.2.30)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.4.7)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.29.22)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.15.0)\n",
            "Installing collected packages: lvis\n",
            "Successfully installed lvis-0.5.3\n",
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1DgFBQ8yCeA"
      },
      "source": [
        "**Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-_7FhXuyAtw",
        "outputId": "7b3c28ab-d48e-4d07-b449-748dcbc2447d"
      },
      "source": [
        "#mount your google drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkZ9o7QiyMmo",
        "outputId": "88c40f9c-0b13-47fd-eb46-20847149d99e"
      },
      "source": [
        "#copy and unzip training folder\n",
        "!cp -r \"/content/gdrive/MyDrive/Juice_Box/SSD/train.zip\" \"/content/tensorflow-object-detection-faster-rcnn/data\"\n",
        "!unzip '/content/tensorflow-object-detection-faster-rcnn/data/train.zip' -d '/content/tensorflow-object-detection-faster-rcnn/data'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/tensorflow-object-detection-faster-rcnn/data/train.zip\n",
            "   creating: /content/tensorflow-object-detection-faster-rcnn/data/round2/\n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle10_jpg.rf.94e003f8976d8ab19a4bf6e9c1357a14.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle10_jpg.rf.94e003f8976d8ab19a4bf6e9c1357a14.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle11_jpg.rf.5aea207a1525a5d0bc153f5b85becc2d.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle11_jpg.rf.5aea207a1525a5d0bc153f5b85becc2d.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle12_jpg.rf.7e2c63fd733f0c7c921a73dee3e0ef9f.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle12_jpg.rf.7e2c63fd733f0c7c921a73dee3e0ef9f.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle13_jpg.rf.963d81fb784379c858201fbf7e7c50d3.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle13_jpg.rf.963d81fb784379c858201fbf7e7c50d3.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle14_jpg.rf.24ff1aa17b40c9e3d9591a725fbeb723.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle14_jpg.rf.24ff1aa17b40c9e3d9591a725fbeb723.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle15_jpg.rf.e589c91757fe0179107caaa4ed080710.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle15_jpg.rf.e589c91757fe0179107caaa4ed080710.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle16_jpg.rf.db349d18ca6cf33a75b03f7d70099603.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle16_jpg.rf.db349d18ca6cf33a75b03f7d70099603.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle17_jpg.rf.53877d2c50116a6b67671130071b1854.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle17_jpg.rf.53877d2c50116a6b67671130071b1854.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle18_jpg.rf.280ee97482e8fafb56be0c3b4557cd75.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle18_jpg.rf.280ee97482e8fafb56be0c3b4557cd75.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle19_jpg.rf.b3efe2cba4da50c9a1f6cea40355bec3.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle19_jpg.rf.b3efe2cba4da50c9a1f6cea40355bec3.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle1_jpg.rf.701ea564d2a9dd5cdd1c56c239bda73e.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle1_jpg.rf.701ea564d2a9dd5cdd1c56c239bda73e.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle20_jpg.rf.33def72ae65d654f05d607c44e02c5a8.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle20_jpg.rf.33def72ae65d654f05d607c44e02c5a8.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle21_jpg.rf.183e836b6f3d0cf472b717dcf6f2f714.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle21_jpg.rf.183e836b6f3d0cf472b717dcf6f2f714.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle22_jpg.rf.cc2e3cec0f69c643fad3a7ff01f72b90.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle22_jpg.rf.cc2e3cec0f69c643fad3a7ff01f72b90.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle23_jpg.rf.dba42429a65d16e89b323acc04836525.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle23_jpg.rf.dba42429a65d16e89b323acc04836525.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle24_jpeg.rf.efe40d6c1a75e05252ab71c56b04ab02.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle24_jpeg.rf.efe40d6c1a75e05252ab71c56b04ab02.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle25_jpeg.rf.813e358c8b402fd9c0f53ed8170a50a8.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle25_jpeg.rf.813e358c8b402fd9c0f53ed8170a50a8.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle26_jpeg.rf.f0c8f925f4b2d2d1a1a3362864057684.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle26_jpeg.rf.f0c8f925f4b2d2d1a1a3362864057684.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle27_jpeg.rf.7e420bac512c4099b094679d439130b3.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle27_jpeg.rf.7e420bac512c4099b094679d439130b3.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle2_jpg.rf.3462005e2d30a1dea21ef7bc25251698.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle2_jpg.rf.3462005e2d30a1dea21ef7bc25251698.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle3_jpg.rf.e9b0f8a688cf17944ad67bf545a4f4cc.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle3_jpg.rf.e9b0f8a688cf17944ad67bf545a4f4cc.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle4_jpg.rf.59fd1127fa15b03038a1c8c38d3e47ff.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle4_jpg.rf.59fd1127fa15b03038a1c8c38d3e47ff.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle5_jpg.rf.bd309b6f04c598057128b2bacccb4d52.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle5_jpg.rf.bd309b6f04c598057128b2bacccb4d52.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle6_jpg.rf.2b01e177e8245d618d92b9c3d9d38dca.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle6_jpg.rf.2b01e177e8245d618d92b9c3d9d38dca.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle7_jpg.rf.3aa7bc41fb768449e65b5bf466bbb07c.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle7_jpg.rf.3aa7bc41fb768449e65b5bf466bbb07c.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle8_jpg.rf.a31c4feaa0c9dc68c06070c5b6a13121.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle8_jpg.rf.a31c4feaa0c9dc68c06070c5b6a13121.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle9_jpg.rf.7160f302cef3410f311f5096d552885a.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/clear_plastic_bottle9_jpg.rf.7160f302cef3410f311f5096d552885a.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup10_jpeg.rf.a9a89506f4fde3ae33b6c3fcf4810376.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup10_jpeg.rf.a9a89506f4fde3ae33b6c3fcf4810376.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup11_jpeg.rf.7f4e2ce7748032e34e4cd33dc707f7c0.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup11_jpeg.rf.7f4e2ce7748032e34e4cd33dc707f7c0.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup12_jpg.rf.1599390555440b2952f18c784c63eb6d.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup12_jpg.rf.1599390555440b2952f18c784c63eb6d.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup13_jpeg.rf.8a73dc23062d8c2431401f70b87ad401.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup13_jpeg.rf.8a73dc23062d8c2431401f70b87ad401.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup14_jpeg.rf.14ae63c5a5901719f7774bd44fcc7e28.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup14_jpeg.rf.14ae63c5a5901719f7774bd44fcc7e28.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup15_jpeg.rf.f204c9eeda76fdd24143255b008d8427.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup15_jpeg.rf.f204c9eeda76fdd24143255b008d8427.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup16_jpeg.rf.939eee2f062e3f42e221b369c9be48f3.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup16_jpeg.rf.939eee2f062e3f42e221b369c9be48f3.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup17_jpeg.rf.df543dc854bb83443e4001dfa360e02a.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup17_jpeg.rf.df543dc854bb83443e4001dfa360e02a.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup18_jpeg.rf.e124eebc9d17e7acca006c6fedbb9034.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup18_jpeg.rf.e124eebc9d17e7acca006c6fedbb9034.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup19_jpeg.rf.81b9eb168479c01fa87455e583e4c49d.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup19_jpeg.rf.81b9eb168479c01fa87455e583e4c49d.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup1_jpg.rf.816d7642f4264fde77d83d50416d6ebc.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup1_jpg.rf.816d7642f4264fde77d83d50416d6ebc.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup20_jpeg.rf.731a1178170b21989f053e8282017215.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup20_jpeg.rf.731a1178170b21989f053e8282017215.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup21_jpeg.rf.ebbd63bf9a0928afe03ebdce1c6544c2.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup21_jpeg.rf.ebbd63bf9a0928afe03ebdce1c6544c2.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup2_jpg.rf.810467b7d994d59c83bbe015c6c9b6ef.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup2_jpg.rf.810467b7d994d59c83bbe015c6c9b6ef.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup3_jpg.rf.841e42c45e556943d9b7d0b0678ba45e.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup3_jpg.rf.841e42c45e556943d9b7d0b0678ba45e.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup4_jpg.rf.c98c3624b8465bcbeeffda4ba2297594.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup4_jpg.rf.c98c3624b8465bcbeeffda4ba2297594.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup5_jpeg.rf.a45c01d79fc43cca6da92db90b1ff925.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup5_jpeg.rf.a45c01d79fc43cca6da92db90b1ff925.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup6_jpeg.rf.1de80883207a5eb67f1446e92019db0d.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup6_jpeg.rf.1de80883207a5eb67f1446e92019db0d.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup7_jpeg.rf.500c5f5e6186cff0f28e0a4ac696673a.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup7_jpeg.rf.500c5f5e6186cff0f28e0a4ac696673a.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup8_jpeg.rf.cd09f8f99cf083b979500b1171fbf2dd.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup8_jpeg.rf.cd09f8f99cf083b979500b1171fbf2dd.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup9_jpeg.rf.b72482de80ff9829d5f630bf44e912f6.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/disposable_plastic_cup9_jpeg.rf.b72482de80ff9829d5f630bf44e912f6.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can10_jpg.rf.6b900bc75f147f86612d5e420f73ca56.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can10_jpg.rf.6b900bc75f147f86612d5e420f73ca56.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can11_jpeg.rf.b5e0463ae8b03bed92abbb07e4a533d5.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can11_jpeg.rf.b5e0463ae8b03bed92abbb07e4a533d5.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can12_jpeg.rf.aca2af7dadb47e4e0a7f35c54220e983.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can12_jpeg.rf.aca2af7dadb47e4e0a7f35c54220e983.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can13_jpg.rf.11703c7feb6f756273f4ea707b8a3aca.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can13_jpg.rf.11703c7feb6f756273f4ea707b8a3aca.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can14_jpg.rf.1c59e29e43e458c1136d04a6c575a4e7.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can14_jpg.rf.1c59e29e43e458c1136d04a6c575a4e7.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can15_jpg.rf.23836041d7fe41ab166b314afae0e655.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can15_jpg.rf.23836041d7fe41ab166b314afae0e655.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can16_jpeg.rf.ffdc9cdedc2d7d3787ddae8f29536f2e.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can16_jpeg.rf.ffdc9cdedc2d7d3787ddae8f29536f2e.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can17_jpg.rf.6409d16affc79a9370f0867c148f2908.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can17_jpg.rf.6409d16affc79a9370f0867c148f2908.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can18_jpg.rf.e8eb14e911cdad2eb7f0f641996f0385.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can18_jpg.rf.e8eb14e911cdad2eb7f0f641996f0385.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can19_jpg.rf.37bec0641dd26ae4c020fca203588996.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can19_jpg.rf.37bec0641dd26ae4c020fca203588996.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can1_jpg.rf.5147a79c48d3b160605cfe551bfc0ad9.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can1_jpg.rf.5147a79c48d3b160605cfe551bfc0ad9.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can20_jpeg.rf.575319eaef9d356a70c642961b8da9b0.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can20_jpeg.rf.575319eaef9d356a70c642961b8da9b0.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can21_jpg.rf.a2f71883e1dcf73baf1d3003c43016a7.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can21_jpg.rf.a2f71883e1dcf73baf1d3003c43016a7.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can2_jpg.rf.ae0ce94d9fc47c77daa5bae32ab92b2f.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can2_jpg.rf.ae0ce94d9fc47c77daa5bae32ab92b2f.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can3_jpg.rf.f0b5b7f391f75c508a34545c5f0e4464.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can3_jpg.rf.f0b5b7f391f75c508a34545c5f0e4464.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can4_jpg.rf.44ab3e63e958be7ff2ac69ad942d2fbc.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can4_jpg.rf.44ab3e63e958be7ff2ac69ad942d2fbc.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can5_jpg.rf.818dfe3bf9a9f7f75e576573eb557afc.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can5_jpg.rf.818dfe3bf9a9f7f75e576573eb557afc.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can6_jpg.rf.c3920307aff7821d6448f6a8c61860f7.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can6_jpg.rf.c3920307aff7821d6448f6a8c61860f7.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can7_jpg.rf.4037d5573fccdc1a142cc28bd7c9d488.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can7_jpg.rf.4037d5573fccdc1a142cc28bd7c9d488.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can8_jpg.rf.13618e8f955864d13100c89fcd0463e0.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can8_jpg.rf.13618e8f955864d13100c89fcd0463e0.xml  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can9_jpg.rf.cc0b8952520a850a77f427714dcc3fe8.jpg  \n",
            "  inflating: /content/tensorflow-object-detection-faster-rcnn/data/round2/drink_can9_jpg.rf.cc0b8952520a850a77f427714dcc3fe8.xml  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY-D9fI0yTFA"
      },
      "source": [
        "#copy test folder\n",
        "!cp -r \"/content/gdrive/MyDrive/Juice_Box/SSD/test\" \"/content/tensorflow-object-detection-faster-rcnn/data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0WJyXrJylVq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PKbBYdy6yf90",
        "outputId": "7f4036d6-211f-4845-a5e1-657d98146c6e"
      },
      "source": [
        "!pip install tensorflow-object-detection-api"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-object-detection-api\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/11/7f6d3c5c4b603cc40b2813059779afb641bd5eb68045c62ca520bfce0359/tensorflow_object_detection_api-0.1.1.tar.gz (577kB)\n",
            "\r\u001b[K     |▋                               | 10kB 24.6MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 30.5MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 22.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 17.7MB/s eta 0:00:01\r\u001b[K     |██▉                             | 51kB 15.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 61kB 14.2MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 15.6MB/s eta 0:00:01\r\u001b[K     |████▌                           | 81kB 15.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 92kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 102kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 112kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 122kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 133kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 143kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 153kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 163kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 174kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 184kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 194kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 204kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 215kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 225kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 235kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 245kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 256kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 266kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 276kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 286kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 296kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 307kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 317kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 327kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 337kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 348kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 358kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 368kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 378kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 389kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 399kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 409kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 419kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 430kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 440kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 450kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 460kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 471kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 481kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 491kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 501kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 512kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 522kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 532kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 542kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 552kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 563kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 573kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 583kB 15.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (7.0.0)\n",
            "Requirement already satisfied: Matplotlib>=2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (3.2.2)\n",
            "Requirement already satisfied: Cython>=0.28.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.29.22)\n",
            "Requirement already satisfied: Protobuf in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (3.12.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (4.2.6)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (1.0.0)\n",
            "Requirement already satisfied: tensorflow in /tensorflow-1.15.2/python3.7 (from tensorflow-object-detection-api) (1.15.2)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.5.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.36.2)\n",
            "Collecting twine\n",
            "  Downloading https://files.pythonhosted.org/packages/42/ad/713372978a8de58a43c507bf62b9c30c3d7b5cda4e972d563b881620a511/twine-3.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from Protobuf->tensorflow-object-detection-api) (54.1.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from Protobuf->tensorflow-object-detection-api) (1.15.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.3.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.0.3)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (7.6.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (4.10.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.6.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.2/python3.7 (from tensorflow->tensorflow-object-detection-api) (1.15.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.2.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.32.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (3.3.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-1.15.2/python3.7 (from tensorflow->tensorflow-object-detection-api) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.2/python3.7 (from tensorflow->tensorflow-object-detection-api) (1.15.0)\n",
            "Collecting colorama>=0.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (3.7.2)\n",
            "Collecting pkginfo>=1.4.2\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/d78e7c299eb5659bc3a036e5a968a399c62bfe0b2aa18baf7d13f43373ba/pkginfo-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.14 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (4.41.1)\n",
            "Collecting keyring>=15.1\n",
            "  Downloading https://files.pythonhosted.org/packages/26/f9/41230ac47f738f1ba66676dc8d3b30ca5b1f9eb0230fc204bcd9836c4ae9/keyring-23.0.1-py3-none-any.whl\n",
            "Collecting readme-renderer>=21.0\n",
            "  Downloading https://files.pythonhosted.org/packages/39/a5/459adfa22ea237f6e8d0fa95ad29d7369579a5eec26f016ab34bb7f8359c/readme_renderer-29.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (2.23.0)\n",
            "Collecting requests-toolbelt!=0.9.0,>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.7MB/s \n",
            "\u001b[?25hCollecting rfc3986>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/78/be/7b8b99fd74ff5684225f50dd0e865393d2265656ef3b4ba9eaaaffe622b8/rfc3986-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (0.9.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (5.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (2.11.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (5.1.2)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (5.0.5)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (5.1.1)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (4.7.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->tensorflow-object-detection-api) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->tensorflow-object-detection-api) (1.0.18)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->tensorflow-object-detection-api) (5.5.0)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->tensorflow-object-detection-api) (1.9.0)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->tensorflow-object-detection-api) (22.0.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (3.5.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (1.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.4.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (3.3.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (1.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow->tensorflow-object-detection-api) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow->tensorflow-object-detection-api) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow->tensorflow-object-detection-api) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->twine->tensorflow-object-detection-api) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->twine->tensorflow-object-detection-api) (3.7.4.3)\n",
            "Collecting jeepney>=0.4.2; sys_platform == \"linux\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/b0/a6ea72741aaac3f37fb96d195e4ee576a103c4c04e279bc6b446a70960e1/jeepney-0.6.0-py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.4MB/s \n",
            "\u001b[?25hCollecting SecretStorage>=3.2; sys_platform == \"linux\"\n",
            "  Downloading https://files.pythonhosted.org/packages/d9/1e/29cd69fdac7391aa51510dfd42aa70b4e6a826c8cd019ee2a8ab9ec0777f/SecretStorage-3.3.1-py3-none-any.whl\n",
            "Requirement already satisfied: docutils>=0.13.1 in /usr/local/lib/python3.7/dist-packages (from readme-renderer>=21.0->twine->tensorflow-object-detection-api) (0.16)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->twine->tensorflow-object-detection-api) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->twine->tensorflow-object-detection-api) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->twine->tensorflow-object-detection-api) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->twine->tensorflow-object-detection-api) (3.0.4)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->tensorflow-object-detection-api) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->tensorflow-object-detection-api) (1.1.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->tensorflow-object-detection-api) (2.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->tensorflow-object-detection-api) (0.2.5)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->tensorflow-object-detection-api) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->tensorflow-object-detection-api) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->tensorflow-object-detection-api) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->tensorflow-object-detection-api) (0.8.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->tensorflow-object-detection-api) (20.9)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->tensorflow-object-detection-api) (0.5.1)\n",
            "Collecting cryptography>=2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 28.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->SecretStorage>=3.2; sys_platform == \"linux\"->keyring>=15.1->twine->tensorflow-object-detection-api) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2; sys_platform == \"linux\"->keyring>=15.1->twine->tensorflow-object-detection-api) (2.20)\n",
            "Building wheels for collected packages: tensorflow-object-detection-api, gast\n",
            "  Building wheel for tensorflow-object-detection-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-object-detection-api: filename=tensorflow_object_detection_api-0.1.1-cp37-none-any.whl size=844515 sha256=9b5578bd2c0b286e3eab5a10a56fa28c7c86c764681fdc676567ee717119d147\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/54/d0/cfca11930c4b2025d40dede77059094070a67cc3e7bd3b285f\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=12976b6396a55a4d9114bdce767de9f6f560dc03fd4c51d6acdaa7c6633836b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built tensorflow-object-detection-api gast\n",
            "Installing collected packages: colorama, pkginfo, jeepney, cryptography, SecretStorage, keyring, readme-renderer, requests-toolbelt, rfc3986, twine, tensorflow-object-detection-api, gast\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed SecretStorage-3.3.1 colorama-0.4.4 cryptography-3.4.7 gast-0.2.2 jeepney-0.6.0 keyring-23.0.1 pkginfo-1.7.0 readme-renderer-29.0 requests-toolbelt-0.9.1 rfc3986-1.4.0 tensorflow-object-detection-api-0.1.1 twine-3.4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERsjE4DryzpG"
      },
      "source": [
        "#Generate csv files for train and test labels\n",
        "!if [ -d '/content/tensorflow-object-detection-faster-rcnn/data/annotations' ]; then rm -r /content/tensorflow-object-detection-faster-rcnn/data/annotations/* ; else mkdir '/content/tensorflow-object-detection-faster-rcnn/data/annotations' && echo \"Directory annotations created\"; fi\n",
        "\n",
        "if os.path.exists(\"/content/tensorflow-object-detection-faster-rcnn/data/annotations/train_labels.csv\"):\n",
        "    os.remove(\"/content/tensorflow-object-detection-faster-rcnn/data/annotations/train_labels.csv\")\n",
        "\n",
        "if os.path.exists(\"/content/tensorflow-object-detection-faster-rcnn/data/annotations/test_labels.csv\"):\n",
        "    os.remove(\"/content/tensorflow-object-detection-faster-rcnn/data/annotations/test_labels.csv\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJUEEdZny5A8",
        "outputId": "1e2c44bf-cd6d-4ca0-db1c-cacea926553f"
      },
      "source": [
        "#Generate csv files for train and test labels within annotations folder\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import shutil\n",
        "\n",
        "annotations = r'/content/tensorflow-object-detection-faster-rcnn/data' \n",
        "if not os.path.exists(annotations):\n",
        "    os.makedirs(annotations)\n",
        "\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            bndbox = member.find('bndbox')\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member.find('name').text,\n",
        "                     int(bndbox.find('xmin').text),\n",
        "                     int(bndbox.find('ymin').text),\n",
        "                     int(bndbox.find('xmax').text),\n",
        "                     int(bndbox.find('ymax').text)\n",
        "                     )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "\n",
        "\n",
        "def main():\n",
        "    xml_df_train = xml_to_csv(\"/content/tensorflow-object-detection-faster-rcnn/data/train/\")\n",
        "    xml_df_train.to_csv('/content/tensorflow-object-detection-faster-rcnn/data/annotations/'+'train_labels.csv', index=None)\n",
        "    xml_df_test = xml_to_csv(\"/content/tensorflow-object-detection-faster-rcnn/data/test/\")\n",
        "    xml_df_test.to_csv('/content/tensorflow-object-detection-faster-rcnn/data/annotations/'+'test_labels.csv', index=None)\n",
        "    print('Successfully converted xml to csv.')\n",
        "\n",
        "%cd \"/content/tensorflow-object-detection-faster-rcnn\"\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/tensorflow-object-detection-faster-rcnn\n",
            "Successfully converted xml to csv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTMSHv30zACo"
      },
      "source": [
        "# Generate tf_label_map.pbtxt in train folder for the classes generated\n",
        "ssd_classes=pd.DataFrame(pd.read_csv(\"/content/tensorflow-object-detection-faster-rcnn/data/annotations/train_labels.csv\")['class'].unique())\n",
        "ssd_classes.drop_duplicates(inplace=True)\n",
        "\n",
        "ssd_classes['id'] = ssd_classes.index\n",
        "\n",
        "def convert_classes(classes, start=1):\n",
        "    msg = ''\n",
        "    for id, name in enumerate(classes, start=start):\n",
        "        msg = msg + \"item {\\n\"\n",
        "        msg = msg + \" id: \" + str(id) + \"\\n\"\n",
        "        msg = msg + \" name: '\" + name + \"'\\n}\\n\\n\"\n",
        "    return msg[:-1]\n",
        "\n",
        "label_map = convert_classes(ssd_classes[0])\n",
        "with open(\"/content/tensorflow-object-detection-faster-rcnn/data/train/\" + \"label_map.pbtxt\", \"w\") as f:\n",
        "    f.write(label_map)\n",
        "    f.close()    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P2YePv9z9lQ"
      },
      "source": [
        "# Generate TF record - Run for train\n",
        "%%capture\n",
        "%cd {repo_dir_path}\n",
        "#FLAGS.remove_flag_values(FLAGS.flag_values_dict())\n",
        "\n",
        "\"\"\"\n",
        "Usage:\n",
        "# Create train data:\n",
        "python generate_tfrecord.py --label_map=<PATH_TO_LABEL_MAP_FILE> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/\n",
        "train_labels.csv --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/train.record\n",
        "\n",
        "# Create test data:\n",
        "python generate_tfrecord.py --label_map=<PATH_TO_LABEL_MAP_FILE> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/\n",
        "test_labels.csv --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/test.record\n",
        "\"\"\"\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"../../models/research\")\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "flags = tf.compat.v1.app.flags\n",
        "flags.DEFINE_string('f','','')\n",
        "flags.DEFINE_string('csv_input', '', 'Path to the CSV input')\n",
        "flags.DEFINE_string('output_path', '', 'Path to output TFRecord')\n",
        "flags.DEFINE_string('img_path', '', 'Path to images')\n",
        "flags.DEFINE_string('label_map', '', 'Path to label map (.pbtxt) file')\n",
        "\n",
        "# if your image has more labels input them as\n",
        "# flags.DEFINE_string('label0', '', 'Name of class[0] label')\n",
        "# flags.DEFINE_string('label1', '', 'Name of class[1] label')\n",
        "# and so on.\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "def class_text_to_int(row_label):\n",
        "    for label_id, label_name in get_label_info():\n",
        "        if row_label == label_name:\n",
        "            return label_id\n",
        "    return 0\n",
        "\n",
        "\n",
        "def get_label_info():\n",
        "    \"\"\"\n",
        "    Generate label info from label map (.pbtxt) file\n",
        "    :return: id, name\n",
        "    \"\"\"\n",
        "    label_info = []\n",
        "    with open(FLAGS.label_map) as fp:\n",
        "        for _, line in enumerate(fp):\n",
        "            if \"id:\" in line:\n",
        "                label_id = int(line.split(\":\")[1])\n",
        "                label_info.append(label_id)\n",
        "            elif \"name:\" in line:\n",
        "                label_name = line.split(\":\")[1].strip().replace(\"'\", \"\")\n",
        "                label_info.append(label_name)\n",
        "\n",
        "    for i in range(0, len(label_info), 2):\n",
        "        yield label_info[i:i + 2]\n",
        "\n",
        "\n",
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    width, height = image.size\n",
        "    filename = group.filename.encode('utf8')\n",
        "    image_format = b'jpg'\n",
        "\n",
        "    # check if the image format is matching with your images.\n",
        "    xmins = []\n",
        "    xmaxs = []\n",
        "    ymins = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for index, row in group.object.iterrows():\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(row['class'].encode('utf8'))\n",
        "        classes.append(class_text_to_int(row['class']))\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "\n",
        "def main(_):\n",
        "    FLAGS.output_path=\"/content/tensorflow-object-detection-faster-rcnn/data/train/train.tfrecord\"\n",
        "    FLAGS.csv_input=\"/content/tensorflow-object-detection-faster-rcnn/data/annotations/train_labels.csv\"\n",
        "    FLAGS.img_path=\"/content/tensorflow-object-detection-faster-rcnn/data/train\"\n",
        "    FLAGS.label_map =\"/content/tensorflow-object-detection-faster-rcnn/data/train/label_map.pbtxt\"\n",
        "    \n",
        "    writer = tf.io.TFRecordWriter(\"/content/tensorflow-object-detection-faster-rcnn/data/train/train.tfrecord\")\n",
        "    path = os.path.join(os.getcwd(), FLAGS.img_path)\n",
        "    examples = pd.read_csv(FLAGS.csv_input)\n",
        "    grouped = split(examples, 'filename')\n",
        "\n",
        "    for group in grouped:\n",
        "        tf_example = create_tf_example(group, path)\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "\n",
        "    writer.close()\n",
        "    output_path = os.path.join(os.getcwd(), FLAGS.output_path)\n",
        "    print('Successfully created the Train TFRecord: {}'.format(output_path))\n",
        "\n",
        "\n",
        "#if __name__ == '__main__':\n",
        "    #tf.compat.v1.run()\n",
        "#    with tf.compat.v1.Session() as sess: sess.run()\n",
        "main(_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j-heHsI0Ub5"
      },
      "source": [
        "# Generate TF record - Run for test\n",
        "%%capture\n",
        "%cd {repo_dir_path}\n",
        "FLAGS.remove_flag_values(FLAGS.flag_values_dict())\n",
        "\n",
        "\"\"\"\n",
        "Usage:\n",
        "# Create train data:\n",
        "python generate_tfrecord.py --label_map=<PATH_TO_LABEL_MAP_FILE> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/\n",
        "train_labels.csv --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/train.record\n",
        "\n",
        "# Create test data:\n",
        "python generate_tfrecord.py --label_map=<PATH_TO_LABEL_MAP_FILE> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/\n",
        "test_labels.csv --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/test.record\n",
        "\"\"\"\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"../../models/research\")\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "flags = tf.compat.v1.app.flags\n",
        "flags.DEFINE_string('f','','')\n",
        "flags.DEFINE_string('csv_input', '', 'Path to the CSV input')\n",
        "flags.DEFINE_string('output_path', '', 'Path to output TFRecord')\n",
        "flags.DEFINE_string('img_path', '', 'Path to images')\n",
        "flags.DEFINE_string('label_map', '', 'Path to label map (.pbtxt) file')\n",
        "\n",
        "# if your image has more labels input them as\n",
        "# flags.DEFINE_string('label0', '', 'Name of class[0] label')\n",
        "# flags.DEFINE_string('label1', '', 'Name of class[1] label')\n",
        "# and so on.\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "def class_text_to_int(row_label):\n",
        "    for label_id, label_name in get_label_info():\n",
        "        if row_label == label_name:\n",
        "            return label_id\n",
        "    return 0\n",
        "\n",
        "\n",
        "def get_label_info():\n",
        "    \"\"\"\n",
        "    Generate label info from label map (.pbtxt) file\n",
        "    :return: id, name\n",
        "    \"\"\"\n",
        "    label_info = []\n",
        "    with open(FLAGS.label_map) as fp:\n",
        "        for _, line in enumerate(fp):\n",
        "            if \"id:\" in line:\n",
        "                label_id = int(line.split(\":\")[1])\n",
        "                label_info.append(label_id)\n",
        "            elif \"name:\" in line:\n",
        "                label_name = line.split(\":\")[1].strip().replace(\"'\", \"\")\n",
        "                label_info.append(label_name)\n",
        "\n",
        "    for i in range(0, len(label_info), 2):\n",
        "        yield label_info[i:i + 2]\n",
        "\n",
        "\n",
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    width, height = image.size\n",
        "    filename = group.filename.encode('utf8')\n",
        "    image_format = b'jpg'\n",
        "\n",
        "    # check if the image format is matching with your images.\n",
        "    xmins = []\n",
        "    xmaxs = []\n",
        "    ymins = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for index, row in group.object.iterrows():\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(row['class'].encode('utf8'))\n",
        "        classes.append(class_text_to_int(row['class']))\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "\n",
        "def main(_):\n",
        "    FLAGS.output_path=\"/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord\"\n",
        "    FLAGS.csv_input=\"/content/tensorflow-object-detection-faster-rcnn/data/annotations/test_labels.csv\"\n",
        "    FLAGS.img_path=\"/content/tensorflow-object-detection-faster-rcnn/data/test\"\n",
        "    FLAGS.label_map =\"/content/tensorflow-object-detection-faster-rcnn/data/test/label_map.pbtxt\"\n",
        "    \n",
        "    writer = tf.io.TFRecordWriter(\"/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord\")\n",
        "    path = os.path.join(os.getcwd(), FLAGS.img_path)\n",
        "    examples = pd.read_csv(FLAGS.csv_input)\n",
        "    grouped = split(examples, 'filename')\n",
        "\n",
        "    for group in grouped:\n",
        "        tf_example = create_tf_example(group, path)\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "\n",
        "    writer.close()\n",
        "    output_path = os.path.join(os.getcwd(), FLAGS.output_path)\n",
        "    print('Successfully created the Test TFRecord: {}'.format(output_path))\n",
        "\n",
        "\n",
        "#if __name__ == '__main__':\n",
        "    #tf.compat.v1.run()\n",
        "#    with tf.compat.v1.Session() as sess: sess.run()\n",
        "main(_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEKOjMejmm9U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ae09f96-d64c-42b1-e0df-41d15b34a8e6"
      },
      "source": [
        "# train set\n",
        "%ls /content/tensorflow-object-detection-faster-rcnn/data/train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clear_plastic_bottle10_jpg.rf.94e003f8976d8ab19a4bf6e9c1357a14.jpg\n",
            "clear_plastic_bottle10_jpg.rf.94e003f8976d8ab19a4bf6e9c1357a14.xml\n",
            "clear_plastic_bottle11_jpg.rf.5aea207a1525a5d0bc153f5b85becc2d.jpg\n",
            "clear_plastic_bottle11_jpg.rf.5aea207a1525a5d0bc153f5b85becc2d.xml\n",
            "clear_plastic_bottle12_jpg.rf.7e2c63fd733f0c7c921a73dee3e0ef9f.jpg\n",
            "clear_plastic_bottle12_jpg.rf.7e2c63fd733f0c7c921a73dee3e0ef9f.xml\n",
            "clear_plastic_bottle13_jpg.rf.963d81fb784379c858201fbf7e7c50d3.jpg\n",
            "clear_plastic_bottle13_jpg.rf.963d81fb784379c858201fbf7e7c50d3.xml\n",
            "clear_plastic_bottle14_jpg.rf.24ff1aa17b40c9e3d9591a725fbeb723.jpg\n",
            "clear_plastic_bottle14_jpg.rf.24ff1aa17b40c9e3d9591a725fbeb723.xml\n",
            "clear_plastic_bottle15_jpg.rf.e589c91757fe0179107caaa4ed080710.jpg\n",
            "clear_plastic_bottle15_jpg.rf.e589c91757fe0179107caaa4ed080710.xml\n",
            "clear_plastic_bottle16_jpg.rf.db349d18ca6cf33a75b03f7d70099603.jpg\n",
            "clear_plastic_bottle16_jpg.rf.db349d18ca6cf33a75b03f7d70099603.xml\n",
            "clear_plastic_bottle17_jpg.rf.53877d2c50116a6b67671130071b1854.jpg\n",
            "clear_plastic_bottle17_jpg.rf.53877d2c50116a6b67671130071b1854.xml\n",
            "clear_plastic_bottle18_jpg.rf.280ee97482e8fafb56be0c3b4557cd75.jpg\n",
            "clear_plastic_bottle18_jpg.rf.280ee97482e8fafb56be0c3b4557cd75.xml\n",
            "clear_plastic_bottle19_jpg.rf.b3efe2cba4da50c9a1f6cea40355bec3.jpg\n",
            "clear_plastic_bottle19_jpg.rf.b3efe2cba4da50c9a1f6cea40355bec3.xml\n",
            "clear_plastic_bottle1_jpg.rf.701ea564d2a9dd5cdd1c56c239bda73e.jpg\n",
            "clear_plastic_bottle1_jpg.rf.701ea564d2a9dd5cdd1c56c239bda73e.xml\n",
            "clear_plastic_bottle20_jpg.rf.33def72ae65d654f05d607c44e02c5a8.jpg\n",
            "clear_plastic_bottle20_jpg.rf.33def72ae65d654f05d607c44e02c5a8.xml\n",
            "clear_plastic_bottle21_jpg.rf.183e836b6f3d0cf472b717dcf6f2f714.jpg\n",
            "clear_plastic_bottle21_jpg.rf.183e836b6f3d0cf472b717dcf6f2f714.xml\n",
            "clear_plastic_bottle22_jpg.rf.cc2e3cec0f69c643fad3a7ff01f72b90.jpg\n",
            "clear_plastic_bottle22_jpg.rf.cc2e3cec0f69c643fad3a7ff01f72b90.xml\n",
            "clear_plastic_bottle23_jpg.rf.dba42429a65d16e89b323acc04836525.jpg\n",
            "clear_plastic_bottle23_jpg.rf.dba42429a65d16e89b323acc04836525.xml\n",
            "clear_plastic_bottle24_jpeg.rf.efe40d6c1a75e05252ab71c56b04ab02.jpg\n",
            "clear_plastic_bottle24_jpeg.rf.efe40d6c1a75e05252ab71c56b04ab02.xml\n",
            "clear_plastic_bottle25_jpeg.rf.813e358c8b402fd9c0f53ed8170a50a8.jpg\n",
            "clear_plastic_bottle25_jpeg.rf.813e358c8b402fd9c0f53ed8170a50a8.xml\n",
            "clear_plastic_bottle26_jpeg.rf.f0c8f925f4b2d2d1a1a3362864057684.jpg\n",
            "clear_plastic_bottle26_jpeg.rf.f0c8f925f4b2d2d1a1a3362864057684.xml\n",
            "clear_plastic_bottle27_jpeg.rf.7e420bac512c4099b094679d439130b3.jpg\n",
            "clear_plastic_bottle27_jpeg.rf.7e420bac512c4099b094679d439130b3.xml\n",
            "clear_plastic_bottle2_jpg.rf.3462005e2d30a1dea21ef7bc25251698.jpg\n",
            "clear_plastic_bottle2_jpg.rf.3462005e2d30a1dea21ef7bc25251698.xml\n",
            "clear_plastic_bottle3_jpg.rf.e9b0f8a688cf17944ad67bf545a4f4cc.jpg\n",
            "clear_plastic_bottle3_jpg.rf.e9b0f8a688cf17944ad67bf545a4f4cc.xml\n",
            "clear_plastic_bottle4_jpg.rf.59fd1127fa15b03038a1c8c38d3e47ff.jpg\n",
            "clear_plastic_bottle4_jpg.rf.59fd1127fa15b03038a1c8c38d3e47ff.xml\n",
            "clear_plastic_bottle5_jpg.rf.bd309b6f04c598057128b2bacccb4d52.jpg\n",
            "clear_plastic_bottle5_jpg.rf.bd309b6f04c598057128b2bacccb4d52.xml\n",
            "clear_plastic_bottle6_jpg.rf.2b01e177e8245d618d92b9c3d9d38dca.jpg\n",
            "clear_plastic_bottle6_jpg.rf.2b01e177e8245d618d92b9c3d9d38dca.xml\n",
            "clear_plastic_bottle7_jpg.rf.3aa7bc41fb768449e65b5bf466bbb07c.jpg\n",
            "clear_plastic_bottle7_jpg.rf.3aa7bc41fb768449e65b5bf466bbb07c.xml\n",
            "clear_plastic_bottle8_jpg.rf.a31c4feaa0c9dc68c06070c5b6a13121.jpg\n",
            "clear_plastic_bottle8_jpg.rf.a31c4feaa0c9dc68c06070c5b6a13121.xml\n",
            "clear_plastic_bottle9_jpg.rf.7160f302cef3410f311f5096d552885a.jpg\n",
            "clear_plastic_bottle9_jpg.rf.7160f302cef3410f311f5096d552885a.xml\n",
            "disposable_plastic_cup10_jpeg.rf.a9a89506f4fde3ae33b6c3fcf4810376.jpg\n",
            "disposable_plastic_cup10_jpeg.rf.a9a89506f4fde3ae33b6c3fcf4810376.xml\n",
            "disposable_plastic_cup11_jpeg.rf.7f4e2ce7748032e34e4cd33dc707f7c0.jpg\n",
            "disposable_plastic_cup11_jpeg.rf.7f4e2ce7748032e34e4cd33dc707f7c0.xml\n",
            "disposable_plastic_cup12_jpg.rf.1599390555440b2952f18c784c63eb6d.jpg\n",
            "disposable_plastic_cup12_jpg.rf.1599390555440b2952f18c784c63eb6d.xml\n",
            "disposable_plastic_cup13_jpeg.rf.8a73dc23062d8c2431401f70b87ad401.jpg\n",
            "disposable_plastic_cup13_jpeg.rf.8a73dc23062d8c2431401f70b87ad401.xml\n",
            "disposable_plastic_cup14_jpeg.rf.14ae63c5a5901719f7774bd44fcc7e28.jpg\n",
            "disposable_plastic_cup14_jpeg.rf.14ae63c5a5901719f7774bd44fcc7e28.xml\n",
            "disposable_plastic_cup15_jpeg.rf.f204c9eeda76fdd24143255b008d8427.jpg\n",
            "disposable_plastic_cup15_jpeg.rf.f204c9eeda76fdd24143255b008d8427.xml\n",
            "disposable_plastic_cup16_jpeg.rf.939eee2f062e3f42e221b369c9be48f3.jpg\n",
            "disposable_plastic_cup16_jpeg.rf.939eee2f062e3f42e221b369c9be48f3.xml\n",
            "disposable_plastic_cup17_jpeg.rf.df543dc854bb83443e4001dfa360e02a.jpg\n",
            "disposable_plastic_cup17_jpeg.rf.df543dc854bb83443e4001dfa360e02a.xml\n",
            "disposable_plastic_cup18_jpeg.rf.e124eebc9d17e7acca006c6fedbb9034.jpg\n",
            "disposable_plastic_cup18_jpeg.rf.e124eebc9d17e7acca006c6fedbb9034.xml\n",
            "disposable_plastic_cup19_jpeg.rf.81b9eb168479c01fa87455e583e4c49d.jpg\n",
            "disposable_plastic_cup19_jpeg.rf.81b9eb168479c01fa87455e583e4c49d.xml\n",
            "disposable_plastic_cup1_jpg.rf.816d7642f4264fde77d83d50416d6ebc.jpg\n",
            "disposable_plastic_cup1_jpg.rf.816d7642f4264fde77d83d50416d6ebc.xml\n",
            "disposable_plastic_cup20_jpeg.rf.731a1178170b21989f053e8282017215.jpg\n",
            "disposable_plastic_cup20_jpeg.rf.731a1178170b21989f053e8282017215.xml\n",
            "disposable_plastic_cup21_jpeg.rf.ebbd63bf9a0928afe03ebdce1c6544c2.jpg\n",
            "disposable_plastic_cup21_jpeg.rf.ebbd63bf9a0928afe03ebdce1c6544c2.xml\n",
            "disposable_plastic_cup2_jpg.rf.810467b7d994d59c83bbe015c6c9b6ef.jpg\n",
            "disposable_plastic_cup2_jpg.rf.810467b7d994d59c83bbe015c6c9b6ef.xml\n",
            "disposable_plastic_cup3_jpg.rf.841e42c45e556943d9b7d0b0678ba45e.jpg\n",
            "disposable_plastic_cup3_jpg.rf.841e42c45e556943d9b7d0b0678ba45e.xml\n",
            "disposable_plastic_cup4_jpg.rf.c98c3624b8465bcbeeffda4ba2297594.jpg\n",
            "disposable_plastic_cup4_jpg.rf.c98c3624b8465bcbeeffda4ba2297594.xml\n",
            "disposable_plastic_cup5_jpeg.rf.a45c01d79fc43cca6da92db90b1ff925.jpg\n",
            "disposable_plastic_cup5_jpeg.rf.a45c01d79fc43cca6da92db90b1ff925.xml\n",
            "disposable_plastic_cup6_jpeg.rf.1de80883207a5eb67f1446e92019db0d.jpg\n",
            "disposable_plastic_cup6_jpeg.rf.1de80883207a5eb67f1446e92019db0d.xml\n",
            "disposable_plastic_cup7_jpeg.rf.500c5f5e6186cff0f28e0a4ac696673a.jpg\n",
            "disposable_plastic_cup7_jpeg.rf.500c5f5e6186cff0f28e0a4ac696673a.xml\n",
            "disposable_plastic_cup8_jpeg.rf.cd09f8f99cf083b979500b1171fbf2dd.jpg\n",
            "disposable_plastic_cup8_jpeg.rf.cd09f8f99cf083b979500b1171fbf2dd.xml\n",
            "disposable_plastic_cup9_jpeg.rf.b72482de80ff9829d5f630bf44e912f6.jpg\n",
            "disposable_plastic_cup9_jpeg.rf.b72482de80ff9829d5f630bf44e912f6.xml\n",
            "drink_can10_jpg.rf.6b900bc75f147f86612d5e420f73ca56.jpg\n",
            "drink_can10_jpg.rf.6b900bc75f147f86612d5e420f73ca56.xml\n",
            "drink_can11_jpeg.rf.b5e0463ae8b03bed92abbb07e4a533d5.jpg\n",
            "drink_can11_jpeg.rf.b5e0463ae8b03bed92abbb07e4a533d5.xml\n",
            "drink_can12_jpeg.rf.aca2af7dadb47e4e0a7f35c54220e983.jpg\n",
            "drink_can12_jpeg.rf.aca2af7dadb47e4e0a7f35c54220e983.xml\n",
            "drink_can13_jpg.rf.11703c7feb6f756273f4ea707b8a3aca.jpg\n",
            "drink_can13_jpg.rf.11703c7feb6f756273f4ea707b8a3aca.xml\n",
            "drink_can14_jpg.rf.1c59e29e43e458c1136d04a6c575a4e7.jpg\n",
            "drink_can14_jpg.rf.1c59e29e43e458c1136d04a6c575a4e7.xml\n",
            "drink_can15_jpg.rf.23836041d7fe41ab166b314afae0e655.jpg\n",
            "drink_can15_jpg.rf.23836041d7fe41ab166b314afae0e655.xml\n",
            "drink_can16_jpeg.rf.ffdc9cdedc2d7d3787ddae8f29536f2e.jpg\n",
            "drink_can16_jpeg.rf.ffdc9cdedc2d7d3787ddae8f29536f2e.xml\n",
            "drink_can17_jpg.rf.6409d16affc79a9370f0867c148f2908.jpg\n",
            "drink_can17_jpg.rf.6409d16affc79a9370f0867c148f2908.xml\n",
            "drink_can18_jpg.rf.e8eb14e911cdad2eb7f0f641996f0385.jpg\n",
            "drink_can18_jpg.rf.e8eb14e911cdad2eb7f0f641996f0385.xml\n",
            "drink_can19_jpg.rf.37bec0641dd26ae4c020fca203588996.jpg\n",
            "drink_can19_jpg.rf.37bec0641dd26ae4c020fca203588996.xml\n",
            "drink_can1_jpg.rf.5147a79c48d3b160605cfe551bfc0ad9.jpg\n",
            "drink_can1_jpg.rf.5147a79c48d3b160605cfe551bfc0ad9.xml\n",
            "drink_can20_jpeg.rf.575319eaef9d356a70c642961b8da9b0.jpg\n",
            "drink_can20_jpeg.rf.575319eaef9d356a70c642961b8da9b0.xml\n",
            "drink_can21_jpg.rf.a2f71883e1dcf73baf1d3003c43016a7.jpg\n",
            "drink_can21_jpg.rf.a2f71883e1dcf73baf1d3003c43016a7.xml\n",
            "drink_can2_jpg.rf.ae0ce94d9fc47c77daa5bae32ab92b2f.jpg\n",
            "drink_can2_jpg.rf.ae0ce94d9fc47c77daa5bae32ab92b2f.xml\n",
            "drink_can3_jpg.rf.f0b5b7f391f75c508a34545c5f0e4464.jpg\n",
            "drink_can3_jpg.rf.f0b5b7f391f75c508a34545c5f0e4464.xml\n",
            "drink_can4_jpg.rf.44ab3e63e958be7ff2ac69ad942d2fbc.jpg\n",
            "drink_can4_jpg.rf.44ab3e63e958be7ff2ac69ad942d2fbc.xml\n",
            "drink_can5_jpg.rf.818dfe3bf9a9f7f75e576573eb557afc.jpg\n",
            "drink_can5_jpg.rf.818dfe3bf9a9f7f75e576573eb557afc.xml\n",
            "drink_can6_jpg.rf.c3920307aff7821d6448f6a8c61860f7.jpg\n",
            "drink_can6_jpg.rf.c3920307aff7821d6448f6a8c61860f7.xml\n",
            "drink_can7_jpg.rf.4037d5573fccdc1a142cc28bd7c9d488.jpg\n",
            "drink_can7_jpg.rf.4037d5573fccdc1a142cc28bd7c9d488.xml\n",
            "drink_can8_jpg.rf.13618e8f955864d13100c89fcd0463e0.jpg\n",
            "drink_can8_jpg.rf.13618e8f955864d13100c89fcd0463e0.xml\n",
            "drink_can9_jpg.rf.cc0b8952520a850a77f427714dcc3fe8.jpg\n",
            "drink_can9_jpg.rf.cc0b8952520a850a77f427714dcc3fe8.xml\n",
            "label_map.pbtxt\n",
            "train.tfrecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgd-fzAIkZlV"
      },
      "source": [
        "test_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord'\n",
        "train_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/train.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8"
      },
      "source": [
        "## Download base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDCj6ihgUMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4754db81-b86c-4f58-97e4-9bc6ac8da430"
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGhvAObeiIix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f861c5-9653-424b-db48-30a1ca8d160a"
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 135M\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
            "drwxr-xr-x 23 root   root  4.0K Mar 29 13:56 ..\n",
            "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
            "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHnxlfRznPP3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c3746d46-22b8-4450-d84e-1da75f527b61"
      },
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD"
      },
      "source": [
        "## Configuring a Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIhw7IdpLuiU"
      },
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG1nCNpUXcRU"
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtCbLF2i0wI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74df191f-2d64-4db7-d1b3-0e4caf6797ad"
      },
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0MEEanocn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "827277f2-2dc0-49aa-d60f-8017d598cc68"
      },
      "source": [
        "!cat {pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    num_classes: 3\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 300\n",
            "        width: 300\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 1\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            truncated_normal_initializer {\n",
            "              stddev: 0.03\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            train: true,\n",
            "            scale: true,\n",
            "            center: true,\n",
            "            decay: 0.9997,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v2'\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          train: true,\n",
            "          scale: true,\n",
            "          center: true,\n",
            "          decay: 0.9997,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid {\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      hard_example_miner {\n",
            "        num_hard_examples: 3000\n",
            "        iou_threshold: 0.99\n",
            "        loss_type: CLASSIFICATION\n",
            "        max_negatives_per_positive: 3\n",
            "        min_negatives_per_image: 3\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 12\n",
            "  optimizer {\n",
            "    rms_prop_optimizer: {\n",
            "      learning_rate: {\n",
            "        exponential_decay_learning_rate {\n",
            "          initial_learning_rate: 0.004\n",
            "          decay_steps: 800720\n",
            "          decay_factor: 0.95\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "      decay: 0.9\n",
            "      epsilon: 1.0\n",
            "    }\n",
            "  }\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  fine_tune_checkpoint_type:  \"detection\"\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 40000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/train.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  num_examples: 8000\n",
            "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
            "  # Remove the below line to evaluate indefinitely.\n",
            "  max_evals: 10\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11w0uO3jFCB"
      },
      "source": [
        "model_dir = '/content/gdrive/MyDrive/Juice_Box/SSD/Checkpoints/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "#!rm -rf {model_dir}\n",
        "#os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23TECXvNezIF"
      },
      "source": [
        "## Run Tensorboard(Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H2PZs-mSCmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b5a0195-fca5-46b5-f47c-90b9da9c541e"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-29 13:57:11--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.196.72.78, 3.209.27.98, 52.1.26.21, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.196.72.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13805791 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.17M  14.0MB/s    in 0.9s    \n",
            "\n",
            "2021-03-29 13:57:13 (14.0 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13805791/13805791]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8o6r1o5SC5M"
      },
      "source": [
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge1OX7gcSC7S"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5GSGxZNh8rp"
      },
      "source": [
        "### Get Tensorboard link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjhPT9iPSJ6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aeeefdc-875f-40bf-eed6-54377328ad01"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://e8f4a6f84e51.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjDHjhKQofT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc171280-5461-4859-a23b-18f565ec3bc0"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps=50000 \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0329 15:57:14.946606 139918458517376 model_lib.py:813] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 50000\n",
            "I0329 15:57:14.946813 139918458517376 config_util.py:552] Maybe overwriting train_steps: 50000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0329 15:57:14.946907 139918458517376 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0329 15:57:14.946994 139918458517376 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0329 15:57:14.947087 139918458517376 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0329 15:57:14.947193 139918458517376 model_lib.py:829] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I0329 15:57:14.947287 139918458517376 model_lib.py:866] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/gdrive/MyDrive/Juice_Box/SSD_Round2/Checkpoints/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f40ce3875d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0329 15:57:14.947714 139918458517376 estimator.py:212] Using config: {'_model_dir': '/content/gdrive/MyDrive/Juice_Box/SSD_Round2/Checkpoints/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f40ce3875d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f40ce3799e0>) includes params argument, but params are not passed to Estimator.\n",
            "W0329 15:57:14.947935 139918458517376 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f40ce3799e0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0329 15:57:14.948462 139918458517376 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0329 15:57:14.948651 139918458517376 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0329 15:57:14.948866 139918458517376 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0329 15:57:14.963184 139918458517376 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/train/train.tfrecord']\n",
            "I0329 15:57:14.984413 139918458517376 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/train/train.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/train/train.tfrecord']\n",
            "I0329 15:57:14.985826 139918458517376 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/train/train.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0329 15:57:14.985950 139918458517376 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0329 15:57:14.986032 139918458517376 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0329 15:57:14.991023 139918458517376 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0329 15:57:15.007734 139918458517376 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:110: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0329 15:57:25.915383 139918458517376 deprecation.py:323] From /content/models/research/object_detection/inputs.py:110: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:94: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0329 15:57:26.071079 139918458517376 deprecation.py:323] From /content/models/research/object_detection/inputs.py:94: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0329 15:57:32.596833 139918458517376 api.py:332] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0329 15:57:36.083463 139918458517376 deprecation.py:323] From /content/models/research/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0329 15:57:39.740760 139918458517376 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0329 15:57:39.914782 139918458517376 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 15:57:42.376996 139918458517376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 15:57:42.405391 139918458517376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 15:57:42.432351 139918458517376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 15:57:42.460560 139918458517376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 15:57:42.489668 139918458517376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 15:57:42.520184 139918458517376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0329 15:57:46.165329 139918458517376 deprecation.py:506] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0329 15:57:51.777207 139918458517376 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0329 15:57:51.778428 139918458517376 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0329 15:57:54.781934 139918458517376 monitored_session.py:240] Graph was finalized.\n",
            "2021-03-29 15:57:54.782395: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2021-03-29 15:57:54.786782: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000189999 Hz\n",
            "2021-03-29 15:57:54.787003: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55afd24d8700 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-03-29 15:57:54.787036: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-03-29 15:57:54.788870: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-03-29 15:57:54.889373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 15:57:54.890059: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55afd24d8380 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-03-29 15:57:54.890089: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2021-03-29 15:57:54.890279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 15:57:54.890854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-29 15:57:54.891176: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-03-29 15:57:54.892555: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-03-29 15:57:54.894058: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-03-29 15:57:54.894431: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-03-29 15:57:54.895908: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-03-29 15:57:54.896667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-03-29 15:57:54.899624: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-29 15:57:54.899746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 15:57:54.900313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 15:57:54.900818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-03-29 15:57:54.900884: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-03-29 15:57:54.902273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-29 15:57:54.902313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-03-29 15:57:54.902327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-03-29 15:57:54.902499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 15:57:54.903058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 15:57:54.903586: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-03-29 15:57:54.903626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/MyDrive/Juice_Box/SSD_Round2/Checkpoints/model.ckpt-49000\n",
            "I0329 15:57:54.908443 139918458517376 saver.py:1284] Restoring parameters from /content/gdrive/MyDrive/Juice_Box/SSD_Round2/Checkpoints/model.ckpt-49000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "W0329 15:57:56.771125 139918458517376 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0329 15:57:57.770984 139918458517376 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0329 15:57:58.044005 139918458517376 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 49000 into /content/gdrive/MyDrive/Juice_Box/SSD_Round2/Checkpoints/model.ckpt.\n",
            "I0329 15:58:06.088668 139918458517376 basic_session_run_hooks.py:606] Saving checkpoints for 49000 into /content/gdrive/MyDrive/Juice_Box/SSD_Round2/Checkpoints/model.ckpt.\n",
            "2021-03-29 15:58:13.685712: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-29 15:58:14.581515: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "INFO:tensorflow:loss = 0.8463429, step = 49000\n",
            "I0329 15:58:15.441915 139918458517376 basic_session_run_hooks.py:262] loss = 0.8463429, step = 49000\n",
            "INFO:tensorflow:global_step/sec: 4.57869\n",
            "I0329 15:58:37.281119 139918458517376 basic_session_run_hooks.py:692] global_step/sec: 4.57869\n",
            "INFO:tensorflow:loss = 1.1568526, step = 49100 (21.840 sec)\n",
            "I0329 15:58:37.282082 139918458517376 basic_session_run_hooks.py:260] loss = 1.1568526, step = 49100 (21.840 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.41528\n",
            "I0329 15:58:55.747383 139918458517376 basic_session_run_hooks.py:692] global_step/sec: 5.41528\n",
            "INFO:tensorflow:loss = 0.49321955, step = 49200 (18.466 sec)\n",
            "I0329 15:58:55.748557 139918458517376 basic_session_run_hooks.py:260] loss = 0.49321955, step = 49200 (18.466 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.37029\n",
            "I0329 15:59:14.368382 139918458517376 basic_session_run_hooks.py:692] global_step/sec: 5.37029\n",
            "INFO:tensorflow:loss = 1.0746789, step = 49300 (18.621 sec)\n",
            "I0329 15:59:14.369346 139918458517376 basic_session_run_hooks.py:260] loss = 1.0746789, step = 49300 (18.621 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.33922\n",
            "I0329 15:59:33.097721 139918458517376 basic_session_run_hooks.py:692] global_step/sec: 5.33922\n",
            "INFO:tensorflow:loss = 0.7452024, step = 49400 (18.729 sec)\n",
            "I0329 15:59:33.098755 139918458517376 basic_session_run_hooks.py:260] loss = 0.7452024, step = 49400 (18.729 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.37534\n",
            "I0329 15:59:51.701184 139918458517376 basic_session_run_hooks.py:692] global_step/sec: 5.37534\n",
            "INFO:tensorflow:loss = 0.8923678, step = 49500 (18.604 sec)\n",
            "I0329 15:59:51.702391 139918458517376 basic_session_run_hooks.py:260] loss = 0.8923678, step = 49500 (18.604 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.36632\n",
            "I0329 16:00:10.335948 139918458517376 basic_session_run_hooks.py:692] global_step/sec: 5.36632\n",
            "INFO:tensorflow:loss = 0.7323457, step = 49600 (18.635 sec)\n",
            "I0329 16:00:10.337576 139918458517376 basic_session_run_hooks.py:260] loss = 0.7323457, step = 49600 (18.635 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.37629\n",
            "I0329 16:00:28.936115 139918458517376 basic_session_run_hooks.py:692] global_step/sec: 5.37629\n",
            "INFO:tensorflow:loss = 0.6646092, step = 49700 (18.600 sec)\n",
            "I0329 16:00:28.937184 139918458517376 basic_session_run_hooks.py:260] loss = 0.6646092, step = 49700 (18.600 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.33301\n",
            "I0329 16:00:47.687273 139918458517376 basic_session_run_hooks.py:692] global_step/sec: 5.33301\n",
            "INFO:tensorflow:loss = 0.62618494, step = 49800 (18.751 sec)\n",
            "I0329 16:00:47.688474 139918458517376 basic_session_run_hooks.py:260] loss = 0.62618494, step = 49800 (18.751 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.37425\n",
            "I0329 16:01:06.294531 139918458517376 basic_session_run_hooks.py:692] global_step/sec: 5.37425\n",
            "INFO:tensorflow:loss = 0.77549446, step = 49900 (18.607 sec)\n",
            "I0329 16:01:06.295458 139918458517376 basic_session_run_hooks.py:260] loss = 0.77549446, step = 49900 (18.607 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 50000 into /content/gdrive/MyDrive/Juice_Box/SSD_Round2/Checkpoints/model.ckpt.\n",
            "I0329 16:01:24.644001 139918458517376 basic_session_run_hooks.py:606] Saving checkpoints for 50000 into /content/gdrive/MyDrive/Juice_Box/SSD_Round2/Checkpoints/model.ckpt.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0329 16:01:24.870572 139918458517376 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "I0329 16:01:26.104657 139918458517376 dataset_builder.py:163] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "I0329 16:01:26.105067 139918458517376 dataset_builder.py:80] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/test.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0329 16:01:26.105206 139918458517376 dataset_builder.py:81] Number of filenames to read: 1\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0329 16:01:27.089224 139918458517376 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 16:01:29.096263 139918458517376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 16:01:29.124751 139918458517376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 16:01:29.152631 139918458517376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 16:01:29.185348 139918458517376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 16:01:29.213259 139918458517376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 16:01:29.240652 139918458517376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0329 16:01:30.127751 139918458517376 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0329 16:01:30.308617 139918458517376 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0329 16:01:30.779295 139918458517376 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-03-29T16:01:30Z\n",
            "I0329 16:01:30.794779 139918458517376 evaluation.py:255] Starting evaluation at 2021-03-29T16:01:30Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0329 16:01:31.205521 139918458517376 monitored_session.py:240] Graph was finalized.\n",
            "2021-03-29 16:01:31.206514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 16:01:31.207005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-29 16:01:31.207117: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-03-29 16:01:31.207152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-03-29 16:01:31.207181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-03-29 16:01:31.207212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-03-29 16:01:31.207237: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-03-29 16:01:31.207260: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-03-29 16:01:31.207284: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-29 16:01:31.207425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 16:01:31.208150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 16:01:31.208601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-03-29 16:01:31.208661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-29 16:01:31.208683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-03-29 16:01:31.208697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-03-29 16:01:31.208827: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 16:01:31.209506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 16:01:31.210007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/MyDrive/Juice_Box/SSD_Round2/Checkpoints/model.ckpt-50000\n",
            "I0329 16:01:31.213671 139918458517376 saver.py:1284] Restoring parameters from /content/gdrive/MyDrive/Juice_Box/SSD_Round2/Checkpoints/model.ckpt-50000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0329 16:01:32.109719 139918458517376 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0329 16:01:32.234265 139918458517376 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 0 images.\n",
            "I0329 16:01:33.938273 139914316084992 coco_evaluation.py:293] Performing evaluation on 0 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0329 16:01:33.938789 139914316084992 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0329 16:01:33.939006 139914316084992 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.00s).\n",
            "Accumulating evaluation results...\n",
            "Please run evaluate() first\n",
            "DONE (t=0.00s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
            "INFO:tensorflow:Finished evaluation at 2021-03-29-16:01:34\n",
            "I0329 16:01:34.010578 139918458517376 evaluation.py:275] Finished evaluation at 2021-03-29-16:01:34\n",
            "INFO:tensorflow:Saving dict for global step 50000: DetectionBoxes_Precision/mAP = -1.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = -1.0, DetectionBoxes_Precision/mAP@.75IOU = -1.0, DetectionBoxes_Recall/AR@1 = -1.0, DetectionBoxes_Recall/AR@10 = -1.0, DetectionBoxes_Recall/AR@100 = -1.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.0, Loss/localization_loss = 0.0, Loss/regularization_loss = 0.3068476, Loss/total_loss = 0.0, global_step = 50000, learning_rate = 0.004, loss = 0.0\n",
            "I0329 16:01:34.010841 139918458517376 estimator.py:2049] Saving dict for global step 50000: DetectionBoxes_Precision/mAP = -1.0, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = -1.0, DetectionBoxes_Precision/mAP@.75IOU = -1.0, DetectionBoxes_Recall/AR@1 = -1.0, DetectionBoxes_Recall/AR@10 = -1.0, DetectionBoxes_Recall/AR@100 = -1.0, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.0, Loss/localization_loss = 0.0, Loss/regularization_loss = 0.3068476, Loss/total_loss = 0.0, global_step = 50000, learning_rate = 0.004, loss = 0.0\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50000: /content/gdrive/MyDrive/Juice_Box/SSD_Round2/Checkpoints/model.ckpt-50000\n",
            "I0329 16:01:34.702470 139918458517376 estimator.py:2109] Saving 'checkpoint_path' summary for global step 50000: /content/gdrive/MyDrive/Juice_Box/SSD_Round2/Checkpoints/model.ckpt-50000\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I0329 16:01:34.703458 139918458517376 exporter.py:410] Performing the final export in the end of training.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0329 16:01:35.033581 139918458517376 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 16:01:37.193299 139918458517376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 16:01:37.222172 139918458517376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 16:01:37.250318 139918458517376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 16:01:37.282555 139918458517376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 16:01:37.309710 139918458517376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0329 16:01:37.338258 139918458517376 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0329 16:01:37.995069 139918458517376 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0329 16:01:37.995387 139918458517376 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I0329 16:01:37.995975 139918458517376 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I0329 16:01:37.996098 139918458517376 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I0329 16:01:37.996181 139918458517376 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I0329 16:01:37.996261 139918458517376 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I0329 16:01:37.996329 139918458517376 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2021-03-29 16:01:37.996833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 16:01:37.997340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-29 16:01:37.997445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-03-29 16:01:37.997480: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-03-29 16:01:37.997505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-03-29 16:01:37.997532: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-03-29 16:01:37.997558: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-03-29 16:01:37.997579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-03-29 16:01:37.997602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-29 16:01:37.997694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 16:01:37.998175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 16:01:37.998603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-03-29 16:01:37.998645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-29 16:01:37.998658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-03-29 16:01:37.998668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-03-29 16:01:37.998771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 16:01:37.999248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-29 16:01:37.999682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/MyDrive/Juice_Box/SSD_Round2/Checkpoints/model.ckpt-50000\n",
            "I0329 16:01:38.003755 139918458517376 saver.py:1284] Restoring parameters from /content/gdrive/MyDrive/Juice_Box/SSD_Round2/Checkpoints/model.ckpt-50000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I0329 16:01:38.451048 139918458517376 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0329 16:01:38.451282 139918458517376 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/gdrive/MyDrive/Juice_Box/SSD_Round2/Checkpoints/export/Servo/temp-b'1617033694'/saved_model.pb\n",
            "I0329 16:01:39.164279 139918458517376 builder_impl.py:425] SavedModel written to: /content/gdrive/MyDrive/Juice_Box/SSD_Round2/Checkpoints/export/Servo/temp-b'1617033694'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 0.6606166.\n",
            "I0329 16:01:39.496034 139918458517376 estimator.py:371] Loss for final step: 0.6606166.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-tUdtnRybs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e9d7df4-d169-4974-929e-116052d2d61f"
      },
      "source": [
        "!ls {model_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\n",
            "eval_0\n",
            "events.out.tfevents.1616990045.230ec628f60b\n",
            "events.out.tfevents.1616993533.230ec628f60b\n",
            "events.out.tfevents.1617026298.06d2b57efd48\n",
            "events.out.tfevents.1617028467.06d2b57efd48\n",
            "events.out.tfevents.1617031245.06d2b57efd48\n",
            "events.out.tfevents.1617033190.06d2b57efd48\n",
            "events.out.tfevents.1617033472.06d2b57efd48\n",
            "export\n",
            "graph.pbtxt\n",
            "model.ckpt-43214.data-00000-of-00001\n",
            "model.ckpt-43214.index\n",
            "model.ckpt-43214.meta\n",
            "model.ckpt-45000.data-00000-of-00001\n",
            "model.ckpt-45000.index\n",
            "model.ckpt-45000.meta\n",
            "model.ckpt-48000.data-00000-of-00001\n",
            "model.ckpt-48000.index\n",
            "model.ckpt-48000.meta\n",
            "model.ckpt-49000.data-00000-of-00001\n",
            "model.ckpt-49000.index\n",
            "model.ckpt-49000.meta\n",
            "model.ckpt-50000.data-00000-of-00001\n",
            "model.ckpt-50000.index\n",
            "model.ckpt-50000.meta\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}